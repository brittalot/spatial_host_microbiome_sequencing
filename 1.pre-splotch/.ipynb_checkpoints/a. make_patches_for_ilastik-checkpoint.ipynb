{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making ST patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import skimage\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "from itertools import chain\n",
    "# set axis \n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "\n",
    "# set image size \n",
    "Image.MAX_IMAGE_PIXELS = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all images available\n",
    "he_path = '/home/sanjavickovic/data/st_data/images'\n",
    "ann_path = '/home/sanjavickovic/data/st_data/annotations'\n",
    "he_filenames = os.listdir(he_path)\n",
    "ann_filenames = os.listdir(ann_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only colon images and annotations\n",
    "metadata = pd.read_excel('/home/sanjavickovic/data/st_data/Metadata_ST.xlsx')\n",
    "\n",
    "# preprocess colons\n",
    "metadata = metadata[metadata['Tissue Type'].isin(['Colon.Normal']) & metadata['Organism'].isin(['Mouse'])]\n",
    "\n",
    "# preprocess bacs\n",
    "#metadata = metadata[metadata['Genotype'].isin(['Bacs.Distal']) & metadata['Organism'].isin(['Mouse'])]\n",
    "\n",
    "# format \n",
    "metadata['Filename'] = [str(i)+'CN'+str(j)+'_'+str(z) for i,j,z in zip(metadata['Array Batch'],metadata['Chip number'],metadata['ArrayIT Well Position'])]\n",
    "metadata = metadata[['Age','Sex', 'Genotype', 'Specimen #ID','Filename']]\n",
    "\n",
    "# select if needed otherwise comment\n",
    "#metadata =  metadata[metadata['Filename'].isin(['10015CN80_C1','10015CN80_C2' ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Specimen #ID</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6w</td>\n",
       "      <td>F</td>\n",
       "      <td>BL6WT.Proximal</td>\n",
       "      <td>M1</td>\n",
       "      <td>L9CN12_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6w</td>\n",
       "      <td>F</td>\n",
       "      <td>BL6WT.Middle</td>\n",
       "      <td>M1</td>\n",
       "      <td>L9CN12_D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6w</td>\n",
       "      <td>F</td>\n",
       "      <td>BL6WT.Distal</td>\n",
       "      <td>M1</td>\n",
       "      <td>L9CN12_E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6w</td>\n",
       "      <td>F</td>\n",
       "      <td>BL6WT.Proximal</td>\n",
       "      <td>M1</td>\n",
       "      <td>L9CN12_C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6w</td>\n",
       "      <td>F</td>\n",
       "      <td>BL6WT.Middle</td>\n",
       "      <td>M1</td>\n",
       "      <td>L9CN12_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>6w</td>\n",
       "      <td>M</td>\n",
       "      <td>Bacs.Distal</td>\n",
       "      <td>M1 6w M (2) 10/05</td>\n",
       "      <td>10015CN67_D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>6w</td>\n",
       "      <td>M</td>\n",
       "      <td>Bacs.Distal</td>\n",
       "      <td>M1 6w M (2) 10/05</td>\n",
       "      <td>10015CN67_E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>6w</td>\n",
       "      <td>M</td>\n",
       "      <td>Bacs.Distal</td>\n",
       "      <td>M1 6w M (2) 10/05</td>\n",
       "      <td>10015CN67_C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>6w</td>\n",
       "      <td>M</td>\n",
       "      <td>Bacs.Distal</td>\n",
       "      <td>M1 6w M (2) 10/05</td>\n",
       "      <td>10015CN67_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>6w</td>\n",
       "      <td>M</td>\n",
       "      <td>Bacs.Distal</td>\n",
       "      <td>M1 6w M (2) 10/05</td>\n",
       "      <td>10015CN67_E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Sex        Genotype       Specimen #ID      Filename\n",
       "67   6w   F  BL6WT.Proximal                 M1     L9CN12_C1\n",
       "68   6w   F    BL6WT.Middle                 M1     L9CN12_D1\n",
       "69   6w   F    BL6WT.Distal                 M1     L9CN12_E1\n",
       "70   6w   F  BL6WT.Proximal                 M1     L9CN12_C2\n",
       "71   6w   F    BL6WT.Middle                 M1     L9CN12_D2\n",
       "..   ..  ..             ...                ...           ...\n",
       "579  6w   M     Bacs.Distal  M1 6w M (2) 10/05  10015CN67_D1\n",
       "580  6w   M     Bacs.Distal  M1 6w M (2) 10/05  10015CN67_E1\n",
       "581  6w   M     Bacs.Distal  M1 6w M (2) 10/05  10015CN67_C2\n",
       "582  6w   M     Bacs.Distal  M1 6w M (2) 10/05  10015CN67_D2\n",
       "583  6w   M     Bacs.Distal  M1 6w M (2) 10/05  10015CN67_E2\n",
       "\n",
       "[455 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to take only colon images to analysis\n",
    "he_files = [value for value in he_filenames if value in [i+'_HE.jpg' for i in metadata['Filename'].tolist()]]\n",
    "ann_files = [value for value in ann_filenames if value in [i+'_annotations.txt' for i in metadata['Filename'].tolist()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_st_images(he_path, ann_path, train_path, he_file):\n",
    "    \n",
    "    print(\"Processing path: \", he_file)\n",
    "    \n",
    "    #reads in he_file_name\n",
    "    filename = os.path.join(he_path, he_file)\n",
    "    \n",
    "    # reads in he_file as image array\n",
    "    image = io.imread(filename, plugin='matplotlib')\n",
    "    xdim,ydim,zdim = image.shape      \n",
    " \n",
    "    #reads in the same annotation file as HE image\n",
    "    #first make sure ann and HE are from the same image\n",
    "    ann_file = os.path.basename(he_file).split(\"_HE.jpg\")[0]+'_annotations.txt'\n",
    "    ann = pd.read_csv(os.path.join(ann_path, ann_file), sep =\"\\t\")\n",
    "    ann_df = pd.DataFrame(ann)\n",
    "    \n",
    "    # gets array dimensions\n",
    "    testy = ydim/32\n",
    "    testx = xdim/34\n",
    "\n",
    "    # transforms x_y into pixel coordinates\n",
    "    x_indices = np.array([(i-1)*testy for i in ann['x']])\n",
    "    y_indices = np.array([(i-1)*testx for i in ann['y']])\n",
    "\n",
    "    x_coordinates = []\n",
    "    y_coordinates = []\n",
    "    for i in x_indices:\n",
    "        for j in y_indices:\n",
    "            x_coordinates.append(i)\n",
    "            y_coordinates.append(j) \n",
    "           \n",
    "    # add correct pixel coordiantes\n",
    "    ann_df['new_x'] = x_indices\n",
    "    ann_df['new_y'] = y_indices\n",
    "\n",
    "    # if ann label \"Unknown\" remove those spots\n",
    "    ann_df = ann_df[~ann_df['value'].isin(['Unknown'])] \n",
    "    \n",
    "    # rename regions to make sure they survive tf handling\n",
    "    new_names = [{x:x.lower().replace(\" - \",\" \").replace(\";\",\" and \")} for x in set(ann_df['value'])]\n",
    "    vals = [v for v in new_names for k,v in v.items()]\n",
    "    keys = [v for v in new_names for v,k in v.items()]\n",
    "    ann_df['value'] = ann_df['value'].replace({keys[i]: vals[i] for i in range(len(vals))})\n",
    "    all_spots = ann_df\n",
    "    \n",
    "    # remove any frame spots as those interfere with size of plots given they're smaller \n",
    "    x_all = np.array([i for i in range(1, 33)])\n",
    "    y_all = np.array([i for i in range(1, 35)])\n",
    "    first_row = [str(x)+'_35' for x in x_all]\n",
    "    last_row = [str(x)+'_1' for x in x_all]\n",
    "    first_column = ['1_'+str(y) for y in y_all]\n",
    "    last_column = ['33_'+str(y) for y in y_all]\n",
    "    frame = np.concatenate([first_row, last_row,first_column,last_column]) # this is generic for any ST array\n",
    "    all_spots = all_spots[~all_spots['x_y'].isin(frame)] \n",
    "    \n",
    "    # chage to train dir \n",
    "    # mkdir dir if it doesnt exist\n",
    "    if os.path.isdir(train_path) == False:\n",
    "        os.mkdir(train_path)\n",
    "    os.chdir(train_path)\n",
    "    print(train_path)\n",
    "    \n",
    "    #print(glob.glob(os.path.join('/home/sanjavickovic/data/st_data/patches', \"*\")))\n",
    "\n",
    "    #read in the RGB image and resize same way \n",
    "    A = matplotlib.pyplot.imread(filename)\n",
    "    \n",
    "    # plots sanity check\n",
    "#     fig, ax = plt.subplots(figsize=(25, 25))\n",
    "\n",
    "#     # visualize the tissue image with annotated spots\n",
    "#     ax.imshow(A, interpolation='none', alpha=1, cmap='gray')\n",
    "\n",
    "#     # visualize the ST spots on top of the tissue image\n",
    "#     ax.scatter(ann_df['new_x'], ann_df['new_y'], alpha = 0.2, s = xdim/15)\n",
    "#     ax.set_aspect('equal')\n",
    "    \n",
    "    # plot small images of annotated spots and save all metadata in labels\n",
    "    xminmax = []\n",
    "    for i in all_spots['new_x']:\n",
    "        xminmax.append((float(i)-xdim/(A.shape[0]/100),float(i)+xdim/(A.shape[0]/100))) # should be around 100 px around in case image is 1500x1500\n",
    "\n",
    "    yminmax = []\n",
    "    for i in all_spots['new_y']:\n",
    "        yminmax.append((float(i)-ydim/(A.shape[0]/120),float(i)+ydim/(A.shape[0]/120))) # should be around 100 px around in case image is 1500x1500\n",
    "    \n",
    "    df1 = pd.DataFrame(xminmax, columns = ['xmin', 'xmax'])\n",
    "    df2 = pd.DataFrame(yminmax, columns = ['ymin', 'ymax'])\n",
    "    df3 = pd.DataFrame(np.array([all_spots['image'],all_spots['x_y'],all_spots['value']])).T\n",
    "    df3.columns = ('image', 'x_y', 'value')\n",
    "    result_tmp = pd.concat([df1,df2], axis=1, sort=False)\n",
    "    results = pd.concat([result_tmp, df3], axis=1, sort=False )\n",
    "\n",
    "    labels = []\n",
    "    for index, row in results.iterrows():\n",
    "        labels.append((row['image']+'_'+row['x_y'],row['value']))\n",
    "\n",
    "        B=A[int(round(row['ymin'])):int(round(row['ymax'])),int(round(row['xmin'])):int(round(row['xmax'])),:]\n",
    "        C=Image.fromarray(B, 'RGB')\n",
    "        \n",
    "        #check if patch exhists in folder; otherwise write image patch\n",
    "        patch_name = train_path+\"/\"+str(row['image']+'_'+row['x_y']+'.jpg')\n",
    "        if not os.path.basename(patch_name) in os.listdir(train_path):\n",
    "            C.save(str(row['image']+'_'+row['x_y']+'.jpg'), quality=95)\n",
    "            print(os.path.basename(patch_name))\n",
    "#         # sets names to our variables\n",
    "#         npa = np.array(labels).T.tolist()\n",
    "\n",
    "#         # write out a csv files acting as labels for all images\n",
    "#         labels_path = \"/Users/sanjavickovic/Desktop/colons_comp/labels\"\n",
    "#         file_labels = os.path.join(labels_path, he_file.split(\"_HE.jpg\")[0].split(\"/\")[-1] + '_labels.csv')\n",
    "#         with open(file_labels,'w') as out:\n",
    "#             file_writer = csv.writer(out)\n",
    "#             file_writer.writerow(('id', 'annotation'))\n",
    "#             for i in range(len(npa[0])):\n",
    "#                 file_writer.writerow([x[i] for x in npa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing path:  /home/sanjavickovic/data/st_data/images/10015CN93_D2_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/10015CN93_D2\n",
      "Processing path:  /home/sanjavickovic/data/st_data/images/10015CN103_D2_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/10015CN103_D2\n",
      "10015CN103_D2_4_20.jpg\n",
      "10015CN103_D2_6_14.jpg\n",
      "10015CN103_D2_26_13.jpg\n",
      "10015CN103_D2_5_15.jpg\n",
      "10015CN103_D2_10_32.jpg\n",
      "10015CN103_D2_11_32.jpg\n",
      "10015CN103_D2_7_14.jpg\n",
      "10015CN103_D2_21_20.jpg\n",
      "10015CN103_D2_6_15.jpg\n",
      "10015CN103_D2_6_13.jpg\n",
      "10015CN103_D2_11_31.jpg\n",
      "10015CN103_D2_11_33.jpg\n",
      "10015CN103_D2_23_18.jpg\n",
      "10015CN103_D2_5_14.jpg\n",
      "10015CN103_D2_7_13.jpg\n",
      "10015CN103_D2_21_19.jpg\n",
      "10015CN103_D2_22_18.jpg\n",
      "10015CN103_D2_20_20.jpg\n",
      "10015CN103_D2_21_18.jpg\n",
      "10015CN103_D2_25_13.jpg\n",
      "10015CN103_D2_22_19.jpg\n",
      "Processing path:  /home/sanjavickovic/data/st_data/images/10015CN92_D2_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/10015CN92_D2\n",
      "10015CN92_D2_6_23.jpg\n",
      "10015CN92_D2_15_15.jpg\n",
      "10015CN92_D2_21_30.jpg\n",
      "Processing path:  /home/sanjavickovic/data/st_data/images/10015CN103_D1_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/10015CN103_D1\n",
      "10015CN103_D1_8_14.jpg\n",
      "10015CN103_D1_19_30.jpg\n",
      "10015CN103_D1_24_14.jpg\n",
      "10015CN103_D1_7_15.jpg\n",
      "10015CN103_D1_7_14.jpg\n",
      "10015CN103_D1_26_15.jpg\n",
      "10015CN103_D1_25_14.jpg\n",
      "10015CN103_D1_10_32.jpg\n",
      "10015CN103_D1_8_15.jpg\n",
      "10015CN103_D1_25_13.jpg\n",
      "10015CN103_D1_27_20.jpg\n",
      "10015CN103_D1_10_33.jpg\n",
      "10015CN103_D1_24_34.jpg\n",
      "10015CN103_D1_23_32.jpg\n",
      "10015CN103_D1_22_11.jpg\n",
      "10015CN103_D1_26_20.jpg\n",
      "10015CN103_D1_27_21.jpg\n",
      "10015CN103_D1_15_34.jpg\n",
      "10015CN103_D1_16_34.jpg\n",
      "10015CN103_D1_24_15.jpg\n",
      "10015CN103_D1_22_31.jpg\n",
      "10015CN103_D1_26_24.jpg\n",
      "10015CN103_D1_24_23.jpg\n",
      "10015CN103_D1_8_13.jpg\n",
      "10015CN103_D1_22_10.jpg\n",
      "10015CN103_D1_7_13.jpg\n",
      "10015CN103_D1_24_24.jpg\n",
      "10015CN103_D1_25_15.jpg\n",
      "10015CN103_D1_17_34.jpg\n",
      "10015CN103_D1_24_13.jpg\n",
      "10015CN103_D1_6_20.jpg\n",
      "10015CN103_D1_26_14.jpg\n",
      "10015CN103_D1_21_8.jpg\n",
      "10015CN103_D1_24_10.jpg\n",
      "10015CN103_D1_25_16.jpg\n",
      "10015CN103_D1_23_15.jpg\n",
      "10015CN103_D1_21_34.jpg\n",
      "Processing path:  /home/sanjavickovic/data/st_data/images/10015CN93_D1_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/10015CN93_D1\n",
      "10015CN93_D1_23_23.jpg\n",
      "10015CN93_D1_25_23.jpg\n",
      "10015CN93_D1_9_17.jpg\n",
      "10015CN93_D1_18_34.jpg\n",
      "10015CN93_D1_25_22.jpg\n",
      "10015CN93_D1_24_22.jpg\n",
      "10015CN93_D1_8_18.jpg\n",
      "10015CN93_D1_24_23.jpg\n",
      "10015CN93_D1_22_24.jpg\n",
      "10015CN93_D1_22_23.jpg\n",
      "10015CN93_D1_24_24.jpg\n",
      "10015CN93_D1_23_24.jpg\n",
      "10015CN93_D1_17_34.jpg\n",
      "10015CN93_D1_10_17.jpg\n",
      "10015CN93_D1_8_17.jpg\n",
      "Processing path:  /home/sanjavickovic/data/st_data/images/L9CN40_D1_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/L9CN40_D1\n",
      "L9CN40_D1_25.071_18.981.jpg\n",
      "Processing path:  /home/sanjavickovic/data/st_data/images/10005CN88_E1_HE.jpg\n",
      "/home/sanjavickovic/data/st_data/patches/10005CN88_E1\n",
      "10005CN88_E1_23.034_27.929.jpg\n"
     ]
    }
   ],
   "source": [
    "train_path = '/home/sanjavickovic/data/st_data/patches'\n",
    "# he_files = glob.glob(he_path+'/'+'*HE.jpg') # for all images\n",
    "he_files = [he_path +\"/\"+i for i in ['10015CN93_D2_HE.jpg', '10015CN103_D2_HE.jpg', '10015CN92_D2_HE.jpg' ,'10015CN103_D1_HE.jpg', '10015CN93_D1_HE.jpg' ,'L9CN40_D1_HE.jpg','10005CN88_E1_HE.jpg']] # for specific images\n",
    "#train_ready = [i for i in os.listdir(train_path)] # for all images\n",
    "\n",
    "for he_file in he_files:\n",
    "    he_tmp = he_file.split(\"/\")[-1]\n",
    "        \n",
    "    # check if this image has already been processed\n",
    "#     if (he_tmp.split(\"_HE.jpg\")[0] in train_ready):\n",
    "#         continue \n",
    "        \n",
    "    he_dir = os.path.join(train_path + '/' + he_tmp.split(\"_\")[0] + '_' + he_tmp.split(\"_\")[1])\n",
    "    \n",
    "    preprocess_st_images(he_path, ann_path, he_dir, he_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
