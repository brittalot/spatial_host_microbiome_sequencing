{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this script in case you used bash to create a BF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import pickle\n",
    "import operator\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multitest as multi\n",
    "from collections import defaultdict\n",
    "from ast import literal_eval\n",
    "import scanpy as sc\n",
    "import csv \n",
    "import anndata\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.size'] = 6\n",
    "pd.set_option(\"display.max_rows\", 50, \"display.max_columns\", 50)\n",
    "sns.set_style(\"ticks\")\n",
    "sc.set_figure_params(scanpy=True, dpi=80, dpi_save=300, frameon=True, vector_friendly=True, fontsize=20, figsize=None, color_map=None, format='pdf', facecolor=None, transparent=False, ipython_format='png2x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "\n",
    "def union(lst1, lst2): \n",
    "    final_list = lst1 + lst2 \n",
    "    return final_list\n",
    "\n",
    "def ftest(aba_spec_cutoff,st_spec_cutoff):\n",
    "    # DIFFERENTIAL GENES PER REGION - Fisher's exact test\n",
    "    bb_count = 0\n",
    "    fisher_dict = {}\n",
    "    pval_list = []\n",
    "\n",
    "    ct = np.unique(aba_spec_cutoff['ident'].tolist())\n",
    "    for condition, df in st_spec_cutoff.groupby('condition_1'):\n",
    "\n",
    "            ####################### Fisher's exact test\n",
    "            #########################################################################\n",
    "            #regions_tmp = list(set(st_spec_cutoff['ABA_aar1'].tolist()))\n",
    "            print(condition)\n",
    "            regions_tmp = list(set(st_spec_cutoff['AAR1'].tolist()))\n",
    "\n",
    "            regions = [x for x in regions_tmp if str(x) != 'nan']\n",
    "\n",
    "            for i in regions:\n",
    "\n",
    "                for j in ct:\n",
    "                    # print(i,j)\n",
    "                    #break\n",
    "\n",
    "                    #ST genes\n",
    "                    #st_genes = df[df['ABA_aar1'] == i]['gene'].tolist()\n",
    "                    st_genes = df[df['AAR1'] == i]['gene_new'].tolist()\n",
    "\n",
    "                    # ABA-genes\n",
    "                    aba_genes = aba_spec_cutoff[aba_spec_cutoff['ident'] == j]['gene'].tolist()\n",
    "\n",
    "                    # ST genes in all other regions\n",
    "                    #st_rest = df[df['ABA_aar1'] != i]['gene'].tolist()\n",
    "                    st_rest = df[df['AAR1'] != i]['gene_new'].tolist()\n",
    "\n",
    "                    # ABA genes in all other regions\n",
    "                    aba_rest = aba_spec_cutoff[aba_spec_cutoff['ident'] != j]['gene'].tolist()\n",
    "\n",
    "                    # g1 = genes in both ST and ABA\n",
    "                    # g2 = genes unique to ST\n",
    "                    # g3 = genes unique to ABA\n",
    "                    # g4 = genes neither in st or aba region but in the other regions\n",
    "\n",
    "                    g1 = len(list(set(st_genes).intersection(aba_genes)))\n",
    "                    g2 = len(list(set(aba_genes).difference(set(st_genes)))) \n",
    "                    g3 = len(list(set(st_genes).difference(set(aba_genes))))\n",
    "                    g4 = len(list(set(st_rest).intersection(aba_rest)))\n",
    "\n",
    "                    # print(list(set(st_genes).intersection(aba_genes)))\n",
    "\n",
    "                    # Fisher's test\n",
    "                    oddsratio, pvalue = stats.fisher_exact([[g4, g2], [g3, g1]], alternative='greater')\n",
    "\n",
    "                    # Store pvalues in list to use for multiple corrections testing\n",
    "                    pval_list.append(pvalue)\n",
    "\n",
    "                    # Store fisher's test results in DF\n",
    "                    ff = [condition, i, j, oddsratio, pvalue, g1,list(set(st_genes).intersection(aba_genes)) ]\n",
    "                    # print(i, j, g1, g2, g3, g4, pvalue)\n",
    "\n",
    "                    if bb_count == 0:\n",
    "                        fisher_dict[bb_count] = ff\n",
    "\n",
    "                        df_ff = pd.DataFrame.from_dict(fisher_dict)\n",
    "\n",
    "                        df_ff['idx'] = ['condition', 'AAR_ST', 'ident','Odds ratio', 'p value', 'Num shared genes', 'shared genes']\n",
    "\n",
    "                        df_ff.set_index('idx', inplace = True)\n",
    "\n",
    "                        bb_count += 1\n",
    "                    else:\n",
    "                        df_ff[bb_count] = ff\n",
    "\n",
    "                        bb_count += 1\n",
    "\n",
    "    # Do multiple testing correction on the pvalues\n",
    "    pp = multi.multipletests(pval_list, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "\n",
    "    df_ff_t = df_ff.T \n",
    "\n",
    "    # Add corrected p-values\n",
    "    df_ff_t['p-value, corrected'] = list(pp[1])\n",
    "    \n",
    "    return df_ff_t\n",
    "\n",
    "def grouped_obs_mean(adata, group_key, layer=None, gene_symbols=None):\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "    if gene_symbols is not None:\n",
    "        new_idx = adata.var[idx]\n",
    "    else:\n",
    "        new_idx = adata.var_names\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=grouped.groups.keys(),\n",
    "        index=adata.var_names\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel(X.mean(axis=0, dtype=np.float64))\n",
    "    return out\n",
    "\n",
    "def cluster_color_map(cc):\n",
    "    # create color map\n",
    "    cmap1 = cm.get_cmap('tab20b')\n",
    "    c1 = [matplotlib.colors.rgb2hex(cmap1(i)) for i in range(cmap1.N)]\n",
    "    cmap2 = cm.get_cmap('tab20c')\n",
    "    c2 = [matplotlib.colors.rgb2hex(cmap2(i)) for i in range(cmap2.N)]\n",
    "    cmap3 = cm.get_cmap('Accent')\n",
    "    c3 = [matplotlib.colors.rgb2hex(cmap3(i)) for i in range(cmap3.N)]\n",
    "    cmap4 = cm.get_cmap('Set2')\n",
    "    c4 = [matplotlib.colors.rgb2hex(cmap4(i)) for i in range(cmap4.N)]\n",
    "    cmap5 = cm.get_cmap('Pastel1')\n",
    "    c5 = [matplotlib.colors.rgb2hex(cmap5(i)) for i in range(cmap5.N)]\n",
    "    cmap6 = cm.get_cmap('Set1')\n",
    "    c6 = [matplotlib.colors.rgb2hex(cmap6(i)) for i in range(cmap6.N)]\n",
    "    cmap7 = cm.get_cmap('Dark2')\n",
    "    c7 = [matplotlib.colors.rgb2hex(cmap7(i)) for i in range(cmap7.N)]\n",
    "    \n",
    "    c = c1 + c2\n",
    "    if cc == 'tab20b':\n",
    "        return c1\n",
    "    if cc == 'tab20c':\n",
    "        return c2    \n",
    "    if cc == 'Accent':\n",
    "        return c3\n",
    "    if cc == 'Set2':\n",
    "        return c4\n",
    "    if cc == 'Pastel1':\n",
    "        return c5\n",
    "    if cc == 'Set1':\n",
    "        return c6\n",
    "    if cc == 'Dark2':\n",
    "        return c7\n",
    "    if cc == 'all':\n",
    "        return c\n",
    "\n",
    "def labeled_clustermap(a, gene, obs_cat,use_common_regions = False):\n",
    "    # pick gene\n",
    "    # gene = ['Tff3', 'Actb']\n",
    "\n",
    "    # pre-process for common areas\n",
    "    tmp =  a[:,gene]\n",
    "    # obs_cat = ['Genotype', 'Sex', 'annotation','Specimen_ID'] #, 'Sex','Specimen_ID'\n",
    "    preproc = grouped_obs_mean(tmp, obs_cat).T\n",
    "\n",
    "    # Set levels variable to empty \n",
    "    ann_multiindex = []\n",
    "    region_multiindex = []\n",
    "    age_multiindex = []\n",
    "    sex_multiindex = []\n",
    "    id_multiindex = []\n",
    "\n",
    "    # get index location\n",
    "    if 'annotation' in obs_cat:\n",
    "        ann_multiindex = np.where(np.asarray(obs_cat) == \"annotation\")[0][0]\n",
    "    if 'Genotype' in obs_cat:\n",
    "        region_multiindex = np.where(np.asarray(obs_cat) == \"Genotype\")[0][0]\n",
    "    if 'Age' in obs_cat:\n",
    "        age_multiindex = np.where(np.asarray(obs_cat) == \"Age\")[0][0]\n",
    "    if 'Sex' in obs_cat:\n",
    "        sex_multiindex = np.where(np.asarray(obs_cat) == \"Sex\")[0][0]\n",
    "    if 'Specimen_ID' in obs_cat:\n",
    "        id_multiindex = np.where(np.asarray(obs_cat) == \"Specimen_ID\")[0][0]\n",
    "\n",
    "    # get expression info\n",
    "    gene_df = preproc\n",
    "\n",
    "\n",
    "    columns = []\n",
    "    if gene_df.index.nlevels > 1:\n",
    "        for i in range(0,len(gene_df.index[0])):\n",
    "            if i != ann_multiindex:\n",
    "                columns.append(gene_df.index.get_level_values(i))\n",
    "    else:\n",
    "        columns.append(gene_df.index)\n",
    "\n",
    "    if ann_multiindex:\n",
    "        htdata2 = pd.pivot_table(gene_df,  values=gene_df.columns, \n",
    "                             columns=[gene_df.index.get_level_values(ann_multiindex)], \n",
    "                             index = columns,\n",
    "                                 fill_value=min(gene_df.min()))\n",
    "    else:\n",
    "        htdata2 = pd.pivot_table(gene_df,  values=gene_df.columns, \n",
    "                         index = columns,\n",
    "                             fill_value=min(gene_df.min()))\n",
    "\n",
    "    \n",
    "    # subset to common areas\n",
    "    if ann_multiindex:\n",
    "        if use_common_regions == True:\n",
    "            htdata2 = htdata2.loc[:, (htdata2 != min(htdata2.min())).all(axis=0)]\n",
    "    \n",
    "    # set dendogram cluster colors\n",
    "    row_colors = []\n",
    "    columns_colors = []\n",
    "    cat_cols_dict = dict()\n",
    "    row_colors_dict = dict()\n",
    "    if htdata2.index.nlevels > 1:\n",
    "        for i in range(0,len(htdata2.index[0])):       \n",
    "                # color first category\n",
    "                if i == 0:\n",
    "                    c = cluster_color_map('Accent')\n",
    "                if i == 1:\n",
    "                    c = cluster_color_map('Set2')\n",
    "                if i == 2:\n",
    "                    c = cluster_color_map('Set1')\n",
    "                if i == 3:\n",
    "                    c = cluster_color_map('Pastel1')\n",
    "                row_cols = dict(zip(np.unique([j for j in htdata2.index.get_level_values(i)]), c))\n",
    "                row_color = pd.Series([j for j in htdata2.index.get_level_values(i)]).map(row_cols)\n",
    "                row_color.name = obs_cat[i]\n",
    "                row_colors.append(row_color)\n",
    "                row_colors_dict.update(row_cols)\n",
    "    else:\n",
    "        c = cluster_color_map('Accent')\n",
    "        row_color = dict(zip(np.unique([j for j in htdata2.index]), c))\n",
    "        row_colors = pd.Series([j for j in htdata2.index]).map(row_color)\n",
    "        row_colors_dict = row_color\n",
    "        row_colors.name = obs_cat[0]\n",
    "\n",
    "    if htdata2.columns.nlevels > 1:\n",
    "        for i in range(0,len(htdata2.columns[0])):       \n",
    "                # color first category\n",
    "                if i == 1:\n",
    "                    c = cluster_color_map('all')\n",
    "                if i == 0:\n",
    "                    c = cluster_color_map('Dark2')\n",
    "                cat_cols = dict(zip(np.unique([j for j in htdata2.columns.get_level_values(i)]), c))\n",
    "                col_color = pd.Series([j for j in htdata2.columns.get_level_values(i)]).map(cat_cols)\n",
    "                if i == 1:\n",
    "                    col_color.name = 'annotation'\n",
    "                else:\n",
    "                    col_color.name = 'Genes'\n",
    "                columns_colors.append(col_color)\n",
    "                cat_cols_dict.update(cat_cols)\n",
    "    else:\n",
    "        c = cluster_color_map('Dark2')\n",
    "        cat_cols = dict(zip(np.unique([j for j in htdata2.columns]), c))\n",
    "        columns_colors = pd.Series([j for j in htdata2.columns]).map(cat_cols)\n",
    "        cat_cols_dict = cat_cols\n",
    "        columns_colors.name = 'Genes'\n",
    "\n",
    "    if not isinstance(columns_colors, list): \n",
    "        columns_colors = [columns_colors]\n",
    "    if not isinstance(row_colors, list): \n",
    "        row_colors = [row_colors]\n",
    "\n",
    "    # gets final colors \n",
    "    rcol = pd.DataFrame(row_colors).T\n",
    "    rcol.index = htdata2.index\n",
    "    ccol = pd.DataFrame(columns_colors).T\n",
    "    ccol.index = htdata2.columns\n",
    "\n",
    "    # print(\"DE results for gene:\", gene)\n",
    "\n",
    "    # Plot heatmap\n",
    "    sns.set(font_scale=.45)\n",
    "    sns.set_style('ticks')\n",
    "\n",
    "    hb = sns.clustermap(htdata2,row_cluster=False, vmin = 0, row_colors = rcol, col_colors = ccol,\n",
    "                        col_cluster=False, cmap = 'magma', linewidth = 0.05, \n",
    "                        linecolor = 'black', cbar_kws={'label': u'lambda', 'pad':0})\n",
    "    plt.setp(hb.ax_heatmap.get_yticklabels(), rotation=0, ha=\"left\",\n",
    "         rotation_mode=\"anchor\")\n",
    "    hb.ax_heatmap.set_xlabel('')\n",
    "    hb.ax_heatmap.set_ylabel('')\n",
    "    handles = [Patch(facecolor={**cat_cols_dict, **row_colors_dict}[name]) for name in {**cat_cols_dict, **row_colors_dict}]\n",
    "    plt.legend(handles, {**cat_cols_dict, **row_colors_dict}, title='color annotations',\n",
    "               bbox_to_anchor=(0, 1), bbox_transform=plt.gcf().transFigure, loc='upper right')\n",
    "\n",
    "    return hb\n",
    "\n",
    "#Define cluster score for individual genes\n",
    "def marker_gene_expression(anndata, marker_dict, gene_symbol_key=None, partition_key='louvain_r1'):\n",
    "    \"\"\"\n",
    "    A function to get mean z-score expressions of marker genes\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    anndata         - An AnnData object containing the data set and a partition\n",
    "    #    marker_dict     - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or \n",
    "    #                      an anndata.var field with the key given by the gene_symbol_key input\n",
    "    #    gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker \n",
    "    #                      genes\n",
    "    #    partition_key   - The key for the anndata.obs field where the cluster IDs are stored. The default is\n",
    "    #                      'louvain_r1' \n",
    "    \"\"\"\n",
    "\n",
    "    #Test inputs\n",
    "    if partition_key not in anndata.obs.columns.values:\n",
    "        print('KeyError: The partition key was not found in the passed AnnData object.')\n",
    "        print('   Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!')\n",
    "        raise\n",
    "\n",
    "    if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):\n",
    "        print('KeyError: The provided gene symbol key was not found in the passed AnnData object.')\n",
    "        print('   Check that your cell type markers are given in a format that your anndata object knows!')\n",
    "        raise\n",
    "        \n",
    "    if gene_symbol_key:\n",
    "        gene_ids = anndata.var[gene_symbol_key]\n",
    "    else:\n",
    "        gene_ids = anndata.var_names\n",
    "\n",
    "    clusters = anndata.obs[partition_key].cat.categories\n",
    "    n_clust = len(clusters)\n",
    "    marker_exp = pd.DataFrame(columns=clusters)\n",
    "    marker_exp['cell_type'] = pd.Series({}, dtype='str')\n",
    "    marker_names = []\n",
    "    \n",
    "    z_scores = sc.pp.scale(anndata, copy=True)\n",
    "\n",
    "    i = 0\n",
    "    for group in marker_dict:\n",
    "        # Find the corresponding columns and get their mean expression in the cluster\n",
    "        for gene in marker_dict[group]:\n",
    "            ens_idx = np.in1d(gene_ids, gene) #Note there may be multiple mappings\n",
    "            if np.sum(ens_idx) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                z_scores.obs[ens_idx[0]] = z_scores.X[:,ens_idx].mean(1) #works for both single and multiple mapping\n",
    "                ens_idx = ens_idx[0]\n",
    "\n",
    "            clust_marker_exp = z_scores.obs.groupby(partition_key)[ens_idx].apply(np.mean).tolist()\n",
    "            clust_marker_exp.append(group)\n",
    "            marker_exp.loc[i] = clust_marker_exp\n",
    "            marker_names.append(gene)\n",
    "            i+=1\n",
    "\n",
    "    #Replace the rownames with informative gene symbols\n",
    "    marker_exp.index = marker_names\n",
    "\n",
    "    return(marker_exp)\n",
    "\n",
    "def splotch2anndata(ST_top_gene_dict, a, mode):\n",
    "    \"\"\"\n",
    "    A function to add DE genes as ranked genes to scanpy anndata object\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    a                  - An AnnData object containing the data set and a partition:conditions and annotation\n",
    "    #    ST_top_gene_dict   - A pd.DataFrame with fields: age_1, age_2, region_1, region_2, AAR1, AAR2, logsBFs (list), Delta (list), genes (list)  \n",
    "    #    mode               - A string denotype type of analysis to be collected: annotation_analysis,genotype_analysis,temporal_analysis\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### Add DE genes as ranked genes to scanpy anndata object\n",
    "\n",
    "    # make sure something to merge on\n",
    "    ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "    # filters ST_top for 'Annotation analysis'\n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] == 'Rest')]\n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'Rest')]\n",
    "    if mode == 'temporal_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'Rest')]\n",
    "    ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes']]\n",
    "    ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['annotation'], keep='first').reset_index(drop=True)\n",
    "\n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "    rank_genes_groups['names'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['names'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['logfoldchanges'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['pvals'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "\n",
    "    # creates markers dict\n",
    "    tmp = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = ann_pd_merged['annotation'])\n",
    "    markers_dict_annotation_analysis = {}\n",
    "    for i,j in enumerate(tmp.index):\n",
    "        y = tmp.iloc[i,:]\n",
    "        markers_dict_annotation_analysis[j] = [x for x in y if str(x) != 'nan']\n",
    "\n",
    "    \n",
    "    # makes zscores\n",
    "    marker_gene_expressions = marker_gene_expression(a, markers_dict_annotation_analysis, gene_symbol_key=None, partition_key='annotation')\n",
    "    marker_gene_expressions = marker_gene_expressions.drop(labels='cell_type', axis=1).to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['scores'] = marker_gene_expressions\n",
    "    \n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    #atest = a.copy()\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "    \n",
    "def splotch2anndata_v3(ST_top_gene_dict, a, mode, conditions_order = None):\n",
    "    \n",
    "    #ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    #a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "\n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "\n",
    "    # filters ST_top for 'Annotation analysis'\n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] == 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['AAR1'], right_on = ['annotation'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1', 'region_1', 'AAR1']]\n",
    "        ann_pd_merged['dups'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['annotation'])  \n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['annotation'].isin(conditions_order)]\n",
    "               \n",
    "        \n",
    "        #inx_name = [i+'_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'])]\n",
    "        inx_name = [i for i in ann_pd_merged['annotation']]\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "        #ann_pd_merged['age1_region1'] = [i+\"_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'])]\n",
    "        ann_pd_merged['age1_region1'] = [i for i in ann_pd_merged['annotation']]\n",
    "        means_pd_index = ann_pd_merged.groupby('age1_region1')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        #for cond in means_pd_index['age1_region1']:\n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(inx_name):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            sub = means_pd_index[means_pd_index['age1_region1'] == cond]['index'].iloc[0]\n",
    "            asub = a[a.obs.index.isin(sub)]\n",
    "            asub = asub[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            #asub = asub[:,rank_genes_groups['names'][cond]]\n",
    "            asub.obs['merging'] = cond\n",
    "            asub.var_names_make_unique()\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] != ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['region_1'], right_on = ['Region'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        ann_pd_merged['region1_region2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['region1_region2'])\n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['region1_region2'].isin(conditions_order)]\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "        \n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        means_pd_index = ann_pd_merged.groupby('region1_region2')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        #for cond in means_pd_index['region1_region2']:\n",
    "        #    cond_names.append(cond)\n",
    "        \n",
    "        #ann_pd_merged['index'] = inx_name   \n",
    "        for cond in conditions_order:\n",
    "            if not cond in list(inx_name):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            sub = means_pd_index[means_pd_index['region1_region2'] == cond]['index'].iloc[0]\n",
    "            asub = a[a.obs.index.isin(sub)]\n",
    "            asub = asub[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            #asub = asub[:,rank_genes_groups['names'][cond]]\n",
    "            asub.obs['merging'] = cond\n",
    "            asub.var_names_make_unique()\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    if mode == 'temporal_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        #ann_pd['age1_age2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd['age_1'], ann_pd['age_2'])]\n",
    "        #print(np.unique(ann_pd['age1_age2']))\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['age_1'], right_on = ['Age'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','age_2', 'region_1']]\n",
    "        #ann_pd_merged['age1_age2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #print(np.unique(ann_pd_merged['age1_age2']))\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        \n",
    "        ann_pd_merged['age1_age2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #print(np.unique(ann_pd_merged['age1_age2']))\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['age1_age2'])\n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['age1_age2'].isin(conditions_order)]\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #ann_pd_merged['index'] = inx_name \n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        means_pd_index = ann_pd_merged.groupby('age1_age2')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        #for cond in means_pd_index['age1_age2']:\n",
    "        #    cond_names.append(cond)\n",
    "            \n",
    "           \n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(inx_name):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            sub = means_pd_index[means_pd_index['age1_age2'] == cond]['index'].iloc[0]\n",
    "            asub = a[a.obs.index.isin(sub)]\n",
    "            asub = asub[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            #asub = asub[:,rank_genes_groups['names'][cond]]\n",
    "            asub.obs['merging'] = cond\n",
    "            asub.var_names_make_unique()\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "\n",
    "\n",
    "def splotch2anndata_v2(ST_top_gene_dict, a, mode):\n",
    "    \"\"\"\n",
    "    A function to add DE genes as ranked genes to scanpy anndata object\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    a                  - An AnnData object containing the data set and a partition:conditions and annotation\n",
    "    #    ST_top_gene_dict   - A pd.DataFrame with fields: age_1, age_2, region_1, region_2, AAR1, AAR2, logsBFs (list), Delta (list), genes (list)  \n",
    "    #    mode               - A string denotype type of analysis to be collected: annotation_analysis,genotype_analysis,temporal_analysis\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "    # filters ST_top for 'Annotation analysis'\n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] == 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes','age_1', 'region_1', 'AAR1']]\n",
    "        ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        inx_name = [i+'_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'])]\n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] != ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "    if mode == 'temporal_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes','age_1','age_2', 'region_1']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        \n",
    "        \n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "    #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "    rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "    rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "    # creates markers dict\n",
    "    tmp_genes = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)\n",
    "    tmp_bfs = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)\n",
    "    tmp_deltas = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)\n",
    "    markers_dict_annotation_analysis = {}\n",
    "    bfs_dict_annotation_analysis = {}\n",
    "    deltas_dict_annotation_analysis = {}\n",
    "    for i,j in enumerate(tmp_genes.index):\n",
    "        y = tmp_genes.iloc[i,:]\n",
    "        k = tmp_bfs.iloc[i,:]\n",
    "        l = tmp_deltas.iloc[i,:]\n",
    "        markers_dict_annotation_analysis[j] = [x for x in y if str(x) != 'nan']\n",
    "        bfs_dict_annotation_analysis[j] = [x for x in k if str(x) != 'nan']\n",
    "        deltas_dict_annotation_analysis[j] = [x for x in l if str(x) != 'nan']\n",
    "\n",
    "    # makes zscores\n",
    "    marker_gene_expressions = marker_gene_expression(a, markers_dict_annotation_analysis, gene_symbol_key=None, partition_key='annotation')\n",
    "    marker_gene_expressions = marker_gene_expressions.drop(labels='cell_type', axis=1).to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['scores'] = marker_gene_expressions\n",
    "\n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "    \n",
    "    \n",
    "    \n",
    "    a.obs['index'] = a.obs.index\n",
    "\n",
    "def splotch2anndata_v4(ST_top_gene_dict, a, mode, conditions_order = None):    \n",
    "\n",
    "    ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "    if mode == 'temporal_analysis':\n",
    "        \n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['age_1'], right_on = ['Age'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','age_2', 'region_1']]\n",
    "        #ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        ann_pd_merged['age'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #ann_pd_merged['age'] = [i for i in ann_pd_merged['age_1']]\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['age'])\n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['age'].isin(conditions_order)]\n",
    "        #print(np.unique(ann_pd_merged.age))\n",
    "\n",
    "        #makes sure unique gene names per group\n",
    "        tmp = ann_pd_merged.groupby(\"age\").sum()\n",
    "        tmp = tmp.replace(to_replace='None', value=np.nan).dropna()\n",
    "        ann_pd_merged_tmp = pd.DataFrame(columns = ['genes', 'Delta', 'logBFs'])\n",
    "        for i,j in enumerate(tmp.index):\n",
    "            gn_inx = list(np.unique(list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            bfs_ind = np.argsort(np.array([list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]]))[::-1]\n",
    "            ann_pd_merged_tmp.at[i,'genes'] = [[list(tmp.iloc[i,:]['genes'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'Delta'] = [[list(tmp.iloc[i,:]['Delta'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'logBFs'] = [[list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "        ann_pd_merged_tmp['age'] = tmp.index\n",
    "        inx_name = ann_pd_merged_tmp['age']\n",
    "\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        #means_pd_index = ann_pd_merged_tmp.groupby('age')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        for cond in conditions_order:\n",
    "            if not cond in list(ann_pd_merged_tmp['age']):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            asub = a[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            asub.obs['merging'] = cond\n",
    "            sc.pp.scale(asub, max_value=10)\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "        \n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] != ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'], ann_pd_merged['annotation'])]\n",
    "        #ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        ann_pd_merged['region'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['region_1'],ann_pd_merged['region_2'])]\n",
    "        #ann_pd_merged['region'] = [i for i in ann_pd_merged['region_1']]\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['region'])\n",
    "        \n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['region'].isin(conditions_order)]\n",
    "\n",
    "        #makes sure unique gene names per group\n",
    "        tmp = ann_pd_merged.groupby(\"region\").sum()\n",
    "        tmp = tmp.replace(to_replace='None', value=np.nan).dropna()\n",
    "        ann_pd_merged_tmp = pd.DataFrame(columns = ['genes', 'Delta', 'logBFs'])\n",
    "        for i,j in enumerate(tmp.index):\n",
    "            gn_inx = list(np.unique(list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            bfs_ind = np.argsort(np.array([list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]]))[::-1]\n",
    "            ann_pd_merged_tmp.at[i,'genes'] = [[list(tmp.iloc[i,:]['genes'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'Delta'] = [[list(tmp.iloc[i,:]['Delta'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'logBFs'] = [[list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "        ann_pd_merged_tmp['region'] = tmp.index\n",
    "        inx_name = ann_pd_merged_tmp['region']\n",
    "\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        #means_pd_index = ann_pd_merged_tmp.groupby('age')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(ann_pd_merged_tmp['region']):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            asub = a[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            asub.obs['merging'] = cond\n",
    "            sc.pp.scale(asub, max_value=10)\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)        \n",
    "        \n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'],  ann_pd_merged['annotation'])]\n",
    "        #ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['annotation'])  \n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['annotation'].isin(conditions_order)]\n",
    "\n",
    "        #makes sure unique gene names per group\n",
    "        tmp = ann_pd_merged.groupby(\"annotation\").sum()\n",
    "        tmp = tmp.replace(to_replace='None', value=np.nan).dropna()\n",
    "        ann_pd_merged_tmp = pd.DataFrame(columns = ['genes', 'Delta', 'logBFs'])\n",
    "        for i,j in enumerate(tmp.index):\n",
    "            gn_inx = list(np.unique(list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            #gn_inx = list((list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            bfs_ind = np.argsort(np.array([list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]]))[::-1]\n",
    "            ann_pd_merged_tmp.at[i,'genes'] = [[list(tmp.iloc[i,:]['genes'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'Delta'] = [[list(tmp.iloc[i,:]['Delta'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'logBFs'] = [[list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "        ann_pd_merged_tmp['annotation'] = tmp.index\n",
    "        inx_name = ann_pd_merged_tmp['annotation']\n",
    "\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        #means_pd_index = ann_pd_merged_tmp.groupby('age')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(ann_pd_merged_tmp['annotation']):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            asub = a[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            asub.obs['merging'] = cond\n",
    "            sc.pp.scale(asub, max_value=10)\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "\n",
    "def filter_rank_genes_groups(\n",
    "    adata,\n",
    "    key=None,\n",
    "    key_added='rank_genes_groups_filtered',\n",
    "    min_fold_change=0,\n",
    "    min_pvals_change=0.5,\n",
    "    min_scores=0\n",
    ") -> None:\n",
    "\n",
    "    if key is None:\n",
    "        key = 'rank_genes_groups'\n",
    "\n",
    "    # convert structured numpy array into DataFrame\n",
    "    gene_names = pd.DataFrame(adata.uns[key]['names'])\n",
    "    \n",
    "    #gets unique names\n",
    "    genes_new = pd.DataFrame(columns = gene_names.columns)\n",
    "    for cond, ind in enumerate(gene_names):\n",
    "        genes_tmp = []\n",
    "        for i in range(0,len(gene_names[ind])):\n",
    "            if str(gene_names[ind][i]) in genes_tmp:\n",
    "                genes_new.at[i, ind] = np.nan\n",
    "            else:\n",
    "                if gene_names[ind][i] == 'nan':\n",
    "                    gene_names[ind][i] = np.nan\n",
    "                genes_new.at[i, ind] = gene_names[ind][i]\n",
    "            genes_tmp.append(gene_names[ind][i])\n",
    "    gene_names = genes_new    \n",
    "\n",
    "    fold_change_matrix = pd.DataFrame(adata.uns[key]['logfoldchanges'])\n",
    "    pvals_change_matrix = pd.DataFrame(adata.uns[key]['pvals'])\n",
    "    scores_change_matrix = pd.DataFrame(adata.uns[key]['scores'])\n",
    "    \n",
    "    # filter original_matrix\n",
    "    gene_names = gene_names[(fold_change_matrix >= min_fold_change)]\n",
    "    gene_names = gene_names[(pvals_change_matrix >= min_pvals_change)]\n",
    "    gene_names = gene_names[(scores_change_matrix >= min_scores)]\n",
    "    fold_change_matrix = fold_change_matrix[(fold_change_matrix >= min_fold_change)]\n",
    "    pvals_change_matrix = pvals_change_matrix[(pvals_change_matrix >= min_pvals_change)]  \n",
    "    scores_change_matrix = scores_change_matrix[(scores_change_matrix >= min_scores)]\n",
    "    \n",
    "    # create new structured array using 'key_added'.\n",
    "    adata.uns[key_added] = adata.uns[key].copy()\n",
    "    adata.uns[key_added]['names'] = gene_names.to_records(index=False,column_dtypes='O')\n",
    "    adata.uns[key_added]['logfoldchanges'] = fold_change_matrix.to_records(index=False,column_dtypes='float32')\n",
    "    adata.uns[key_added]['pvals'] = pvals_change_matrix.to_records(index=False,column_dtypes='float64')\n",
    "    adata.uns[key_added]['pvals_adj'] = pvals_change_matrix.to_records(index=False,column_dtypes='float64')\n",
    "    adata.uns[key_added]['scores'] = scores_change_matrix.to_records(index=False,column_dtypes='float32')\n",
    "\n",
    "def filter_BFs(st_spec):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function that filters the BF files from cloud\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    st_spec             - BF data frame\n",
    "    #    ST_top_gene_dict   - A pd.DataFrame with fields: age_1, age_2, region_1, region_2, AAR1, AAR2, logsBFs (list), Delta (list), genes (list)  \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    # do some renaming\n",
    "    st_spec = st_spec[st_spec['BF'] != inf]\n",
    "\n",
    "    # Log10 BF\n",
    "    st_spec['BF'] = np.float64(st_spec['BF'])\n",
    "    x = np.log(st_spec['BF'])\n",
    "    x[x == -inf] = sys.float_info.min # makes sure no inf\n",
    "    x[x == inf] = sys.float_info.max # makes sure no inf\n",
    "    st_spec['logBF'] = x\n",
    "\n",
    "    # rename gene names\n",
    "    st_spec['gene_new'] = [i.split(\"_\")[0] for i in st_spec['gene']]\n",
    "    st_spec['genotype_1'] = [i.split(\" \")[0] for i in st_spec['condition_1']]\n",
    "    st_spec['sex_1'] = [i.split(\" \")[1] for i in st_spec['condition_1']]\n",
    "    st_spec['genotype_2'] = [i.split(\" \")[0] for i in st_spec['condition_2']]\n",
    "    st_spec['sex_2'] = [i.split(\" \")[1] for i in st_spec['condition_2']]    \n",
    "    print('done clean up')\n",
    "    ## Top 100 ST genes per condition and per region\n",
    "    ST_top_gene_dict = pd.DataFrame(columns = ['genotype_1', 'genotype_2', 'sex_1', 'sex_2', 'AAR1', 'AAR2', 'genes', 'logBFs', 'Delta'])\n",
    "    counter = 0\n",
    "    df_group = st_spec.groupby(['genotype_1', 'genotype_2', 'sex_1', 'sex_2', 'AAR1', 'AAR2'])\n",
    "    for label, dfs in df_group: # this is for splotch_one_level\n",
    "\n",
    "        # this gets genes super specific against the whole rest of the datset\n",
    "\n",
    "        #if (label[5] == 'Rest'):\n",
    "\n",
    "        #print(counter)\n",
    "\n",
    "        #dfs = df[(df['logBF'] > 2) & (df['Delta'] > 0)]\n",
    "        #dfs = dfs[(dfs['logBF'] > 0)& (dfs['Delta'] > 0)]\n",
    "        #dfs = df\n",
    "        #print(df.sort_values(by='logBF', ascending=False)['gene_new'].head(5).tolist())\n",
    "        if (len(dfs.sort_values(by='logBF', ascending=False)['gene_new'].head(5).tolist()) == 0):\n",
    "            continue\n",
    "\n",
    "        ST_top_gene_dict.at[counter, 'genotype_1'] = label[0]\n",
    "        ST_top_gene_dict.at[counter, 'genotype_2'] = label[1]\n",
    "        ST_top_gene_dict.at[counter, 'sex_1'] = label[2]\n",
    "        ST_top_gene_dict.at[counter, 'sex_2'] = label[3]\n",
    "        ST_top_gene_dict.at[counter, 'AAR1'] = label[4]\n",
    "        ST_top_gene_dict.at[counter, 'AAR2'] = label[5]\n",
    "        ST_top_gene_dict.at[counter, 'genes'] = dfs.sort_values(by=['logBF', 'Delta'], ascending=[False, False])['gene_new'].tolist()\n",
    "        ST_top_gene_dict.at[counter, 'logBFs'] = dfs.sort_values(by=['logBF', 'Delta'], ascending=[False, False])['logBF'].tolist()\n",
    "        ST_top_gene_dict.at[counter, 'Delta'] = dfs.sort_values(by=['logBF', 'Delta'], ascending=[False, False])['Delta'].tolist()\n",
    "        counter += 1\n",
    "    \n",
    "    return ST_top_gene_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads in tsv file and makes a dataframe for bacterial comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  1  out of:  35\n",
      "Reading chunk:  2  out of:  35\n",
      "Reading chunk:  3  out of:  35\n",
      "Reading chunk:  4  out of:  35\n",
      "Reading chunk:  5  out of:  35\n",
      "Reading chunk:  6  out of:  35\n",
      "Reading chunk:  7  out of:  35\n",
      "Reading chunk:  8  out of:  35\n",
      "Reading chunk:  9  out of:  35\n",
      "Reading chunk:  10  out of:  35\n",
      "Reading chunk:  11  out of:  35\n",
      "Reading chunk:  12  out of:  35\n",
      "Reading chunk:  13  out of:  35\n",
      "Reading chunk:  14  out of:  35\n",
      "Reading chunk:  15  out of:  35\n",
      "Reading chunk:  16  out of:  35\n",
      "Reading chunk:  17  out of:  35\n",
      "Reading chunk:  18  out of:  35\n",
      "Reading chunk:  19  out of:  35\n",
      "Reading chunk:  20  out of:  35\n",
      "Reading chunk:  21  out of:  35\n",
      "Reading chunk:  22  out of:  35\n",
      "Reading chunk:  23  out of:  35\n",
      "Reading chunk:  24  out of:  35\n",
      "Reading chunk:  25  out of:  35\n",
      "Reading chunk:  26  out of:  35\n",
      "Reading chunk:  27  out of:  35\n",
      "Reading chunk:  28  out of:  35\n",
      "Reading chunk:  29  out of:  35\n",
      "Reading chunk:  30  out of:  35\n",
      "Reading chunk:  31  out of:  35\n",
      "Reading chunk:  32  out of:  35\n",
      "Reading chunk:  33  out of:  35\n",
      "Reading chunk:  34  out of:  35\n",
      "Reading chunk:  35  out of:  35\n"
     ]
    }
   ],
   "source": [
    "# Load ST files  \n",
    "path = '/home/sanjavickovic/data/host-microbiome_data/splotch_outputs/wt_gf_zeros/'\n",
    "\n",
    "# Read file\n",
    "filename = os.path.join(path, 'BF.tsv.gz')\n",
    "\n",
    "# makes initial pd\n",
    "fields = ['gene', 'condition_1', 'condition_2', 'AAR1', 'AAR2', 'BF', 'Delta']\n",
    "# reader = pd.read_csv(filename, sep='\\t', chunksize=int(100000), engine='python', skipinitialspace=True, usecols=fields)    \n",
    "\n",
    "# # makes small pkl files\n",
    "# for i, chunk in enumerate(reader):\n",
    "#     out_file = path + \"data_subset_{}.pkl\".format(i+1)\n",
    "#     print(\"Processing chunk: \", i+1)\n",
    "#     with open(out_file, \"wb\") as f:\n",
    "#         pickle.dump(chunk,f,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# arranges pkl files into a df\n",
    "data_p_files=[]\n",
    "for name in glob.glob(path + \"data_subset_*.pkl\"):\n",
    "       data_p_files.append(name)\n",
    "df_bf = pd.DataFrame([])\n",
    "for i in range(len(data_p_files)):\n",
    "    #if i % 20 == 0:\n",
    "    print(\"Reading chunk: \", i+1, ' out of: ', len(data_p_files))\n",
    "    tmp = pd.read_pickle(data_p_files[i])\n",
    "    tmp = tmp[tmp['gene'] != 'gene']    \n",
    "    tmp['BF'] = tmp['BF'].astype(float)\n",
    "    tmp['Delta'] = tmp['Delta'].astype(float)\n",
    "    tmp = tmp[(tmp['BF']>0) & (tmp['Delta']>0)]\n",
    "    df_bf = df_bf.append(tmp,ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Subset anndata and ST_dict to same genes'\n",
    "'Read in large anndata'\n",
    "a = sc.read_h5ad('/home/sanjavickovic/data/host-microbiome_data/st_data/anndata_hm_norm_all_Feb2022.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Add WT bacterial lambdas in place'\n",
    "def rename_lambdas_index(lambdas_file): \n",
    "    nwe=[]\n",
    "    nm=lambdas_file.index\n",
    "    for item in nm:\n",
    "        nwe.append(str(item).split(\"_\")[0])\n",
    "    return nwe\n",
    "\n",
    "# Load Lambda pmean df as from gcp\n",
    "path = '/home/sanjavickovic/data/host-microbiome_data/splotch_outputs/wt_gf_zeros'\n",
    "\n",
    "# Read expression file\n",
    "filename = os.path.join(path, 'lambdas_python.tsv.gz')  \n",
    "lambda_posterior_means = pd.read_csv(filename, index_col=0, low_memory=False, header=[0,1], sep=',') \n",
    "\n",
    "#rename genes\n",
    "lambda_posterior_means.index = rename_lambdas_index(lambda_posterior_means)\n",
    "\n",
    "#rename columns \n",
    "count_files = lambda_posterior_means.columns.map('_'.join).str.strip('_')\n",
    "count_files_names = [i.split(\"/\")[-1].replace(\"_stdata_adjusted.tsv\", \"\") for i in count_files]\n",
    "lambda_posterior_means.columns = count_files_names\n",
    "\n",
    "# Take exp()\n",
    "lambda_posterior_means = lambda_posterior_means.astype(float)\n",
    "lambda_posterior_means = np.exp(lambda_posterior_means-1)\n",
    "\n",
    "#prep lamdas\n",
    "lambda_posterior_means_t = lambda_posterior_means.T\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.loc[:,~lambda_posterior_means_t.columns.str.startswith('coordinate')]\n",
    "\n",
    "# subset to bacteria only\n",
    "#lambda_posterior_means_t = lambda_posterior_means_t[[i for i in lambda_posterior_means_t.columns if i.endswith(\"Bacteria\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subset to GF\"\n",
    "# a_gf = a[~a.obs.index.isin(lambda_posterior_means_t.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subset to WT\"\n",
    "# a_wt = a[a.obs.index.isin(lambda_posterior_means_t.index)]\n",
    "# lambda_posterior_means_t = lambda_posterior_means_t.reindex(a_wt.obs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subset WT to bac vs. genes\"\n",
    "# a_wt_bac = a_wt[:,a_wt.var_names.isin(lambda_posterior_means_t.columns)]\n",
    "# a_wt_bac.X = lambda_posterior_means_t.values\n",
    "# a_wt_genes = a_wt[:,~a_wt.var_names.isin(lambda_posterior_means_t.columns)]\n",
    "# a_wt_n = a_wt.copy()\n",
    "# a_wt_n.X = np.concatenate((a_wt_genes.X, a_wt_bac.X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Make new anndata\"\n",
    "# a_n = a_wt_n.concatenate(a_gf)\n",
    "# a_n.obs.drop([\"batch\", \"Gnai3\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Put in new lambdas with exhisting observations'\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.reindex(a.obs.index)\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.dropna()\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.loc[:,~lambda_posterior_means_t.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = a.obs.loc[lambda_posterior_means_t.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puts in new lambdas into \n",
    "a_n = anndata.AnnData(X = lambda_posterior_means_t.values, obs = obs)\n",
    "a_n.var_names = lambda_posterior_means_t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two extra bacteria\n",
    "#a_n = a_n[:,a_n.var_names.isin([i for i in a_n.var_names if 'Lacrimispora' not in i])]\n",
    "#a_n = a_n[:,a_n.var_names.isin([i for i in a_n.var_names if 'Acetobacterium' not in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Adds bacterial to genes expression lambdas'\n",
    "a_n.write_h5ad(filename = '/home/sanjavickovic/data/host-microbiome_data/st_data/anndata_hm_norm_all_n_Feb2022.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Filter to get only bacteria'\n",
    "df_bf['gene_new'] = [i.split(\"_\")[0] for i in df_bf.gene]\n",
    "#df_bf = df_bf.loc[[i[0] for i in enumerate(df_bf.gene_new) if i[1] in a.var_names]]\n",
    "#df_bf.reset_index(inplace = True)\n",
    "# df_bf.condition_1 = 'WT F'\n",
    "# df_bf.condition_2 = 'WT F'\n",
    "\n",
    "'This are the wt bacterial comparisons'\n",
    "tmp = df_bf[(df_bf.AAR2 == 'Rest')&(df_bf.condition_1 == df_bf.condition_2) &(df_bf.condition_1 == 'WT F')]\n",
    "tmp_bac = tmp[tmp.gene.isin([i for i in tmp.gene if \"Bacteria\" in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two additional bacteria\n",
    "tmp_bac = tmp_bac[tmp_bac.gene.isin([i for i in tmp_bac.gene if \"Lacrimispora\" not in i])]\n",
    "tmp_bac = tmp_bac[tmp_bac.gene.isin([i for i in tmp_bac.gene if \"Acetobacterium\" not in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_wt_vs_gf = df_bf[(df_bf.condition_1 == 'WT F') & ((df_bf.condition_2 == 'GF F') | (df_bf.condition_2 == 'GF M')) & (df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i]))]\n",
    "tmp_gf_vs_wt = df_bf[((df_bf.condition_1 == 'GF F') | (df_bf.condition_1 == 'GF M')) & (df_bf.condition_2 == 'WT F') & (df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two additional bacteria\n",
    "tmp_wt_vs_gf = tmp_wt_vs_gf[tmp_wt_vs_gf.gene.isin([i for i in tmp_wt_vs_gf.gene if \"Lacrimispora\" not in i])]\n",
    "tmp_wt_vs_gf = tmp_wt_vs_gf[tmp_wt_vs_gf.gene.isin([i for i in tmp_wt_vs_gf.gene if \"Acetobacterium\" not in i])]\n",
    "tmp_gf_vs_wt = tmp_gf_vs_wt[tmp_gf_vs_wt.gene.isin([i for i in tmp_gf_vs_wt.gene if \"Acetobacterium\" not in i])]\n",
    "tmp_gf_vs_wt = tmp_gf_vs_wt[tmp_gf_vs_wt.gene.isin([i for i in tmp_gf_vs_wt.gene if \"Lacrimispora\" not in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_wt1 = df_bf[~df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads in tsv file and makes a dataframe for wt vs gf gene comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load ST files  \n",
    "# path = '/home/brittalotstedt/host-microbiome/data/bfs/'\n",
    "\n",
    "# # Read file\n",
    "# filename = os.path.join(path, 'BF.tsv.gz')\n",
    "\n",
    "# # makes initial pd\n",
    "# fields = ['gene', 'condition_1', 'condition_2', 'AAR1', 'AAR2', 'BF', 'Delta']\n",
    "# # reader = pd.read_csv(filename, sep='\\t', chunksize=int(2000000), engine='python', skipinitialspace=True, usecols=fields)    \n",
    "\n",
    "# # # makes small pkl files\n",
    "# # for i, chunk in enumerate(reader):\n",
    "# #     out_file = path + \"data_subset_{}.pkl\".format(i+1)\n",
    "# #     print(\"Processing chunk: \", i+1)\n",
    "# #     with open(out_file, \"wb\") as f:\n",
    "# #         pickle.dump(chunk,f,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # arranges pkl files into a df\n",
    "# data_p_files=[]\n",
    "# for name in glob.glob(path + \"data_subset*.pkl\"):\n",
    "#        data_p_files.append(name)\n",
    "# df_bf = pd.DataFrame([])\n",
    "# for i in range(len(data_p_files)):\n",
    "#     #if i % 20 == 0:\n",
    "#     print(\"Reading chunk: \", i+1, ' out of: ', len(data_p_files))\n",
    "#     tmp = pd.read_pickle(data_p_files[i])\n",
    "#     tmp = tmp[tmp['gene'] != 'gene']    \n",
    "#     tmp['BF'] = tmp['BF'].astype(float)\n",
    "#     tmp['Delta'] = tmp['Delta'].astype(float)\n",
    "#     tmp = tmp[(tmp['BF']>0) & (tmp['Delta']>0)]\n",
    "#     df_bf = df_bf.append(tmp,ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Remove bacterial comparisons from df file'\n",
    "# df_bf['gene_new'] = [i.split(\"_\")[0] for i in df_bf.gene]\n",
    "# #tmp_wt_vs_gf = df_bf[(df_bf.condition_1 == 'WT F') & ((df_bf.condition_2 == 'GF F') | (df_bf.condition_2 == 'GF M')) & (df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i]))]\n",
    "# tmp_wt = df_bf[~df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bf_combined = pd.concat([tmp_bac, tmp_wt1, tmp_wt_vs_gf, tmp_gf_vs_wt])\n",
    "df_bf_combined.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>condition_1</th>\n",
       "      <th>condition_2</th>\n",
       "      <th>AAR1</th>\n",
       "      <th>AAR2</th>\n",
       "      <th>BF</th>\n",
       "      <th>Delta</th>\n",
       "      <th>gene_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67351</th>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "      <td>GF M</td>\n",
       "      <td>WT F</td>\n",
       "      <td>crypt apex and crypt mid</td>\n",
       "      <td>crypt apex and crypt mid</td>\n",
       "      <td>0.813667</td>\n",
       "      <td>0.517438</td>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67352</th>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "      <td>GF F</td>\n",
       "      <td>WT F</td>\n",
       "      <td>crypt apex and crypt mid</td>\n",
       "      <td>crypt apex and crypt mid</td>\n",
       "      <td>0.828057</td>\n",
       "      <td>0.475269</td>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67356</th>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "      <td>GF M</td>\n",
       "      <td>WT F</td>\n",
       "      <td>crypt base</td>\n",
       "      <td>crypt base</td>\n",
       "      <td>1.139173</td>\n",
       "      <td>0.041422</td>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67358</th>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "      <td>GF F</td>\n",
       "      <td>WT F</td>\n",
       "      <td>crypt base</td>\n",
       "      <td>crypt base</td>\n",
       "      <td>1.143385</td>\n",
       "      <td>0.057198</td>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67360</th>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "      <td>GF M</td>\n",
       "      <td>WT F</td>\n",
       "      <td>crypt mid</td>\n",
       "      <td>crypt mid</td>\n",
       "      <td>1.116510</td>\n",
       "      <td>0.156776</td>\n",
       "      <td>Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150554</th>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "      <td>GF F</td>\n",
       "      <td>WT F</td>\n",
       "      <td>mucosa and pellet</td>\n",
       "      <td>mucosa and pellet</td>\n",
       "      <td>1.118850</td>\n",
       "      <td>0.348251</td>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150559</th>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "      <td>GF M</td>\n",
       "      <td>WT F</td>\n",
       "      <td>muscle and submucosa</td>\n",
       "      <td>muscle and submucosa</td>\n",
       "      <td>1.129260</td>\n",
       "      <td>0.269048</td>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150560</th>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "      <td>GF F</td>\n",
       "      <td>WT F</td>\n",
       "      <td>muscle and submucosa</td>\n",
       "      <td>muscle and submucosa</td>\n",
       "      <td>1.113854</td>\n",
       "      <td>0.229289</td>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150562</th>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "      <td>GF M</td>\n",
       "      <td>WT F</td>\n",
       "      <td>pellet</td>\n",
       "      <td>pellet</td>\n",
       "      <td>1.217931</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150563</th>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "      <td>GF F</td>\n",
       "      <td>WT F</td>\n",
       "      <td>pellet</td>\n",
       "      <td>pellet</td>\n",
       "      <td>1.138980</td>\n",
       "      <td>0.439475</td>\n",
       "      <td>Ruthenibacterium-Oscillospiraceae-Eubacteriale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      gene condition_1  \\\n",
       "67351    Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...        GF M   \n",
       "67352    Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...        GF F   \n",
       "67356    Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...        GF M   \n",
       "67358    Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...        GF F   \n",
       "67360    Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...        GF M   \n",
       "...                                                    ...         ...   \n",
       "1150554  Ruthenibacterium-Oscillospiraceae-Eubacteriale...        GF F   \n",
       "1150559  Ruthenibacterium-Oscillospiraceae-Eubacteriale...        GF M   \n",
       "1150560  Ruthenibacterium-Oscillospiraceae-Eubacteriale...        GF F   \n",
       "1150562  Ruthenibacterium-Oscillospiraceae-Eubacteriale...        GF M   \n",
       "1150563  Ruthenibacterium-Oscillospiraceae-Eubacteriale...        GF F   \n",
       "\n",
       "        condition_2                      AAR1                      AAR2  \\\n",
       "67351          WT F  crypt apex and crypt mid  crypt apex and crypt mid   \n",
       "67352          WT F  crypt apex and crypt mid  crypt apex and crypt mid   \n",
       "67356          WT F                crypt base                crypt base   \n",
       "67358          WT F                crypt base                crypt base   \n",
       "67360          WT F                 crypt mid                 crypt mid   \n",
       "...             ...                       ...                       ...   \n",
       "1150554        WT F         mucosa and pellet         mucosa and pellet   \n",
       "1150559        WT F      muscle and submucosa      muscle and submucosa   \n",
       "1150560        WT F      muscle and submucosa      muscle and submucosa   \n",
       "1150562        WT F                    pellet                    pellet   \n",
       "1150563        WT F                    pellet                    pellet   \n",
       "\n",
       "               BF     Delta                                           gene_new  \n",
       "67351    0.813667  0.517438  Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...  \n",
       "67352    0.828057  0.475269  Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...  \n",
       "67356    1.139173  0.041422  Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...  \n",
       "67358    1.143385  0.057198  Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...  \n",
       "67360    1.116510  0.156776  Pseudobutyrivibrio-Lachnospiraceae-Eubacterial...  \n",
       "...           ...       ...                                                ...  \n",
       "1150554  1.118850  0.348251  Ruthenibacterium-Oscillospiraceae-Eubacteriale...  \n",
       "1150559  1.129260  0.269048  Ruthenibacterium-Oscillospiraceae-Eubacteriale...  \n",
       "1150560  1.113854  0.229289  Ruthenibacterium-Oscillospiraceae-Eubacteriale...  \n",
       "1150562  1.217931  0.697431  Ruthenibacterium-Oscillospiraceae-Eubacteriale...  \n",
       "1150563  1.138980  0.439475  Ruthenibacterium-Oscillospiraceae-Eubacteriale...  \n",
       "\n",
       "[235 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_gf_vs_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of the huge df\n",
    "#df_all = df_bf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:828: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:832: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:836: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:837: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:838: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:839: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clean up\n"
     ]
    }
   ],
   "source": [
    "ST_top_gene_dict = filter_BFs(df_bf_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12208"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ST_top_gene_dict.iloc[0]['genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genotype_1</th>\n",
       "      <th>genotype_2</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>AAR1</th>\n",
       "      <th>AAR2</th>\n",
       "      <th>genes</th>\n",
       "      <th>logBFs</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt apex and crypt mid</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Plac8, Slco6c1, Uckl1, Gm12367, Tspear, Mtmr1...</td>\n",
       "      <td>[2.0122117282095053, 1.542921882516165, 1.4583...</td>\n",
       "      <td>[0.65223562354725, 3.8131681028384583, 1.25715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt apex and mucosa</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Mtmr11, Gm32200, Scd4, Cyp2d34, Gimd1, Lyzl4o...</td>\n",
       "      <td>[0.28519925093975473, 0.029994950489092207, -0...</td>\n",
       "      <td>[0.6372250459891668, 1.2219540229105, 0.415214...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt base</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Bpifc, Mapre3, Usp9y, Dydc1, Gm4955, Gm15655,...</td>\n",
       "      <td>[1.0082060694559545, 0.8305594259474725, 0.734...</td>\n",
       "      <td>[2.5167639623125004, 1.8401814456808336, 2.079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt mid</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Ydjc, Aknad1, Stard4, Rnf4, Phb, Ctc1, Smim4,...</td>\n",
       "      <td>[3.4466429431031056, 2.533555270712622, 1.4905...</td>\n",
       "      <td>[1.937673891208333, 4.860282585321833, 0.70985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>epithelium</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Fgf23, Igkv8-31, Npr1, Gm43705, Tnfsf11, Clec...</td>\n",
       "      <td>[0.21825720536127427, -0.06046643125800337, -0...</td>\n",
       "      <td>[0.05216546580691617, 0.7135883506803333, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>mucosa and pellet</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Saa1, Lypd8, Car4, Abcb1a, Sepp1, Hist1h1c, P...</td>\n",
       "      <td>[3.5810409565550567, 1.1435238760455382, 1.131...</td>\n",
       "      <td>[1.142071956405275, 0.5003454392266667, 0.8313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>mucosae and interna</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[P4ha1, Mylk3, Gm3985, Dhx32, Tmem45a, Nog, Gm...</td>\n",
       "      <td>[1.30868985066532, 1.2956374600132459, 1.14272...</td>\n",
       "      <td>[1.1789173022458332, 2.065658233677333, 2.0385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>muscle and submucosa</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Cd2, Lrp8os3, Cyp4a10, Oas1g, Gm38073, 493057...</td>\n",
       "      <td>[0.2730773858106193, 0.17285301481707396, 0.16...</td>\n",
       "      <td>[1.7318922431808335, 0.30870173119785826, 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>pellet</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Clca1, Rbm47, Slc26a3, Saa1, Massilistercora-...</td>\n",
       "      <td>[2.4439504979436975, 0.6585590799053893, 0.574...</td>\n",
       "      <td>[0.31390891916666597, 0.28664277937833305, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>peyer's patch</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[H2-Aa, Tmsb4x, H2-Eb1, Cd74, Mfge8, Ik, H2-Ab...</td>\n",
       "      <td>[200.07019818590464, 44.23749785450635, 22.324...</td>\n",
       "      <td>[2.5447492525905, 0.9646061674999997, 2.530380...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    genotype_1 genotype_2 sex_1 sex_2                      AAR1  AAR2  \\\n",
       "0           GF         GF     F     F  crypt apex and crypt mid  Rest   \n",
       "1           GF         GF     F     F     crypt apex and mucosa  Rest   \n",
       "2           GF         GF     F     F                crypt base  Rest   \n",
       "3           GF         GF     F     F                 crypt mid  Rest   \n",
       "4           GF         GF     F     F                epithelium  Rest   \n",
       "..         ...        ...   ...   ...                       ...   ...   \n",
       "139         WT         WT     F     F         mucosa and pellet  Rest   \n",
       "140         WT         WT     F     F       mucosae and interna  Rest   \n",
       "141         WT         WT     F     F      muscle and submucosa  Rest   \n",
       "142         WT         WT     F     F                    pellet  Rest   \n",
       "143         WT         WT     F     F             peyer's patch  Rest   \n",
       "\n",
       "                                                 genes  \\\n",
       "0    [Plac8, Slco6c1, Uckl1, Gm12367, Tspear, Mtmr1...   \n",
       "1    [Mtmr11, Gm32200, Scd4, Cyp2d34, Gimd1, Lyzl4o...   \n",
       "2    [Bpifc, Mapre3, Usp9y, Dydc1, Gm4955, Gm15655,...   \n",
       "3    [Ydjc, Aknad1, Stard4, Rnf4, Phb, Ctc1, Smim4,...   \n",
       "4    [Fgf23, Igkv8-31, Npr1, Gm43705, Tnfsf11, Clec...   \n",
       "..                                                 ...   \n",
       "139  [Saa1, Lypd8, Car4, Abcb1a, Sepp1, Hist1h1c, P...   \n",
       "140  [P4ha1, Mylk3, Gm3985, Dhx32, Tmem45a, Nog, Gm...   \n",
       "141  [Cd2, Lrp8os3, Cyp4a10, Oas1g, Gm38073, 493057...   \n",
       "142  [Clca1, Rbm47, Slc26a3, Saa1, Massilistercora-...   \n",
       "143  [H2-Aa, Tmsb4x, H2-Eb1, Cd74, Mfge8, Ik, H2-Ab...   \n",
       "\n",
       "                                                logBFs  \\\n",
       "0    [2.0122117282095053, 1.542921882516165, 1.4583...   \n",
       "1    [0.28519925093975473, 0.029994950489092207, -0...   \n",
       "2    [1.0082060694559545, 0.8305594259474725, 0.734...   \n",
       "3    [3.4466429431031056, 2.533555270712622, 1.4905...   \n",
       "4    [0.21825720536127427, -0.06046643125800337, -0...   \n",
       "..                                                 ...   \n",
       "139  [3.5810409565550567, 1.1435238760455382, 1.131...   \n",
       "140  [1.30868985066532, 1.2956374600132459, 1.14272...   \n",
       "141  [0.2730773858106193, 0.17285301481707396, 0.16...   \n",
       "142  [2.4439504979436975, 0.6585590799053893, 0.574...   \n",
       "143  [200.07019818590464, 44.23749785450635, 22.324...   \n",
       "\n",
       "                                                 Delta  \n",
       "0    [0.65223562354725, 3.8131681028384583, 1.25715...  \n",
       "1    [0.6372250459891668, 1.2219540229105, 0.415214...  \n",
       "2    [2.5167639623125004, 1.8401814456808336, 2.079...  \n",
       "3    [1.937673891208333, 4.860282585321833, 0.70985...  \n",
       "4    [0.05216546580691617, 0.7135883506803333, 0.08...  \n",
       "..                                                 ...  \n",
       "139  [1.142071956405275, 0.5003454392266667, 0.8313...  \n",
       "140  [1.1789173022458332, 2.065658233677333, 2.0385...  \n",
       "141  [1.7318922431808335, 0.30870173119785826, 0.32...  \n",
       "142  [0.31390891916666597, 0.28664277937833305, 0.3...  \n",
       "143  [2.5447492525905, 0.9646061674999997, 2.530380...  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST_top_gene_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves formated DE genes df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sanjavickovic/data/host-microbiome_data/splotch_outputs'\n",
    "ST_top_gene_dict.to_csv(os.path.join(path, 'ST_top_gene_dict_BF0_combined.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
