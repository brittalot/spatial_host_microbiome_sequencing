{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this script in case you used bash to create a BF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import pickle\n",
    "import operator\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multitest as multi\n",
    "from collections import defaultdict\n",
    "from ast import literal_eval\n",
    "import scanpy as sc\n",
    "import csv \n",
    "import anndata\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.size'] = 6\n",
    "pd.set_option(\"display.max_rows\", 50, \"display.max_columns\", 50)\n",
    "sns.set_style(\"ticks\")\n",
    "sc.set_figure_params(scanpy=True, dpi=80, dpi_save=300, frameon=True, vector_friendly=True, fontsize=20, figsize=None, color_map=None, format='pdf', facecolor=None, transparent=False, ipython_format='png2x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "\n",
    "def union(lst1, lst2): \n",
    "    final_list = lst1 + lst2 \n",
    "    return final_list\n",
    "\n",
    "def ftest(aba_spec_cutoff,st_spec_cutoff):\n",
    "    # DIFFERENTIAL GENES PER REGION - Fisher's exact test\n",
    "    bb_count = 0\n",
    "    fisher_dict = {}\n",
    "    pval_list = []\n",
    "\n",
    "    ct = np.unique(aba_spec_cutoff['ident'].tolist())\n",
    "    for condition, df in st_spec_cutoff.groupby('condition_1'):\n",
    "\n",
    "            ####################### Fisher's exact test\n",
    "            #########################################################################\n",
    "            #regions_tmp = list(set(st_spec_cutoff['ABA_aar1'].tolist()))\n",
    "            print(condition)\n",
    "            regions_tmp = list(set(st_spec_cutoff['AAR1'].tolist()))\n",
    "\n",
    "            regions = [x for x in regions_tmp if str(x) != 'nan']\n",
    "\n",
    "            for i in regions:\n",
    "\n",
    "                for j in ct:\n",
    "                    # print(i,j)\n",
    "                    #break\n",
    "\n",
    "                    #ST genes\n",
    "                    #st_genes = df[df['ABA_aar1'] == i]['gene'].tolist()\n",
    "                    st_genes = df[df['AAR1'] == i]['gene_new'].tolist()\n",
    "\n",
    "                    # ABA-genes\n",
    "                    aba_genes = aba_spec_cutoff[aba_spec_cutoff['ident'] == j]['gene'].tolist()\n",
    "\n",
    "                    # ST genes in all other regions\n",
    "                    #st_rest = df[df['ABA_aar1'] != i]['gene'].tolist()\n",
    "                    st_rest = df[df['AAR1'] != i]['gene_new'].tolist()\n",
    "\n",
    "                    # ABA genes in all other regions\n",
    "                    aba_rest = aba_spec_cutoff[aba_spec_cutoff['ident'] != j]['gene'].tolist()\n",
    "\n",
    "                    # g1 = genes in both ST and ABA\n",
    "                    # g2 = genes unique to ST\n",
    "                    # g3 = genes unique to ABA\n",
    "                    # g4 = genes neither in st or aba region but in the other regions\n",
    "\n",
    "                    g1 = len(list(set(st_genes).intersection(aba_genes)))\n",
    "                    g2 = len(list(set(aba_genes).difference(set(st_genes)))) \n",
    "                    g3 = len(list(set(st_genes).difference(set(aba_genes))))\n",
    "                    g4 = len(list(set(st_rest).intersection(aba_rest)))\n",
    "\n",
    "                    # print(list(set(st_genes).intersection(aba_genes)))\n",
    "\n",
    "                    # Fisher's test\n",
    "                    oddsratio, pvalue = stats.fisher_exact([[g4, g2], [g3, g1]], alternative='greater')\n",
    "\n",
    "                    # Store pvalues in list to use for multiple corrections testing\n",
    "                    pval_list.append(pvalue)\n",
    "\n",
    "                    # Store fisher's test results in DF\n",
    "                    ff = [condition, i, j, oddsratio, pvalue, g1,list(set(st_genes).intersection(aba_genes)) ]\n",
    "                    # print(i, j, g1, g2, g3, g4, pvalue)\n",
    "\n",
    "                    if bb_count == 0:\n",
    "                        fisher_dict[bb_count] = ff\n",
    "\n",
    "                        df_ff = pd.DataFrame.from_dict(fisher_dict)\n",
    "\n",
    "                        df_ff['idx'] = ['condition', 'AAR_ST', 'ident','Odds ratio', 'p value', 'Num shared genes', 'shared genes']\n",
    "\n",
    "                        df_ff.set_index('idx', inplace = True)\n",
    "\n",
    "                        bb_count += 1\n",
    "                    else:\n",
    "                        df_ff[bb_count] = ff\n",
    "\n",
    "                        bb_count += 1\n",
    "\n",
    "    # Do multiple testing correction on the pvalues\n",
    "    pp = multi.multipletests(pval_list, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "\n",
    "    df_ff_t = df_ff.T \n",
    "\n",
    "    # Add corrected p-values\n",
    "    df_ff_t['p-value, corrected'] = list(pp[1])\n",
    "    \n",
    "    return df_ff_t\n",
    "\n",
    "def grouped_obs_mean(adata, group_key, layer=None, gene_symbols=None):\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "    if gene_symbols is not None:\n",
    "        new_idx = adata.var[idx]\n",
    "    else:\n",
    "        new_idx = adata.var_names\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=grouped.groups.keys(),\n",
    "        index=adata.var_names\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel(X.mean(axis=0, dtype=np.float64))\n",
    "    return out\n",
    "\n",
    "def cluster_color_map(cc):\n",
    "    # create color map\n",
    "    cmap1 = cm.get_cmap('tab20b')\n",
    "    c1 = [matplotlib.colors.rgb2hex(cmap1(i)) for i in range(cmap1.N)]\n",
    "    cmap2 = cm.get_cmap('tab20c')\n",
    "    c2 = [matplotlib.colors.rgb2hex(cmap2(i)) for i in range(cmap2.N)]\n",
    "    cmap3 = cm.get_cmap('Accent')\n",
    "    c3 = [matplotlib.colors.rgb2hex(cmap3(i)) for i in range(cmap3.N)]\n",
    "    cmap4 = cm.get_cmap('Set2')\n",
    "    c4 = [matplotlib.colors.rgb2hex(cmap4(i)) for i in range(cmap4.N)]\n",
    "    cmap5 = cm.get_cmap('Pastel1')\n",
    "    c5 = [matplotlib.colors.rgb2hex(cmap5(i)) for i in range(cmap5.N)]\n",
    "    cmap6 = cm.get_cmap('Set1')\n",
    "    c6 = [matplotlib.colors.rgb2hex(cmap6(i)) for i in range(cmap6.N)]\n",
    "    cmap7 = cm.get_cmap('Dark2')\n",
    "    c7 = [matplotlib.colors.rgb2hex(cmap7(i)) for i in range(cmap7.N)]\n",
    "    \n",
    "    c = c1 + c2\n",
    "    if cc == 'tab20b':\n",
    "        return c1\n",
    "    if cc == 'tab20c':\n",
    "        return c2    \n",
    "    if cc == 'Accent':\n",
    "        return c3\n",
    "    if cc == 'Set2':\n",
    "        return c4\n",
    "    if cc == 'Pastel1':\n",
    "        return c5\n",
    "    if cc == 'Set1':\n",
    "        return c6\n",
    "    if cc == 'Dark2':\n",
    "        return c7\n",
    "    if cc == 'all':\n",
    "        return c\n",
    "\n",
    "def labeled_clustermap(a, gene, obs_cat,use_common_regions = False):\n",
    "    # pick gene\n",
    "    # gene = ['Tff3', 'Actb']\n",
    "\n",
    "    # pre-process for common areas\n",
    "    tmp =  a[:,gene]\n",
    "    # obs_cat = ['Genotype', 'Sex', 'annotation','Specimen_ID'] #, 'Sex','Specimen_ID'\n",
    "    preproc = grouped_obs_mean(tmp, obs_cat).T\n",
    "\n",
    "    # Set levels variable to empty \n",
    "    ann_multiindex = []\n",
    "    region_multiindex = []\n",
    "    age_multiindex = []\n",
    "    sex_multiindex = []\n",
    "    id_multiindex = []\n",
    "\n",
    "    # get index location\n",
    "    if 'annotation' in obs_cat:\n",
    "        ann_multiindex = np.where(np.asarray(obs_cat) == \"annotation\")[0][0]\n",
    "    if 'Genotype' in obs_cat:\n",
    "        region_multiindex = np.where(np.asarray(obs_cat) == \"Genotype\")[0][0]\n",
    "    if 'Age' in obs_cat:\n",
    "        age_multiindex = np.where(np.asarray(obs_cat) == \"Age\")[0][0]\n",
    "    if 'Sex' in obs_cat:\n",
    "        sex_multiindex = np.where(np.asarray(obs_cat) == \"Sex\")[0][0]\n",
    "    if 'Specimen_ID' in obs_cat:\n",
    "        id_multiindex = np.where(np.asarray(obs_cat) == \"Specimen_ID\")[0][0]\n",
    "\n",
    "    # get expression info\n",
    "    gene_df = preproc\n",
    "\n",
    "\n",
    "    columns = []\n",
    "    if gene_df.index.nlevels > 1:\n",
    "        for i in range(0,len(gene_df.index[0])):\n",
    "            if i != ann_multiindex:\n",
    "                columns.append(gene_df.index.get_level_values(i))\n",
    "    else:\n",
    "        columns.append(gene_df.index)\n",
    "\n",
    "    if ann_multiindex:\n",
    "        htdata2 = pd.pivot_table(gene_df,  values=gene_df.columns, \n",
    "                             columns=[gene_df.index.get_level_values(ann_multiindex)], \n",
    "                             index = columns,\n",
    "                                 fill_value=min(gene_df.min()))\n",
    "    else:\n",
    "        htdata2 = pd.pivot_table(gene_df,  values=gene_df.columns, \n",
    "                         index = columns,\n",
    "                             fill_value=min(gene_df.min()))\n",
    "\n",
    "    \n",
    "    # subset to common areas\n",
    "    if ann_multiindex:\n",
    "        if use_common_regions == True:\n",
    "            htdata2 = htdata2.loc[:, (htdata2 != min(htdata2.min())).all(axis=0)]\n",
    "    \n",
    "    # set dendogram cluster colors\n",
    "    row_colors = []\n",
    "    columns_colors = []\n",
    "    cat_cols_dict = dict()\n",
    "    row_colors_dict = dict()\n",
    "    if htdata2.index.nlevels > 1:\n",
    "        for i in range(0,len(htdata2.index[0])):       \n",
    "                # color first category\n",
    "                if i == 0:\n",
    "                    c = cluster_color_map('Accent')\n",
    "                if i == 1:\n",
    "                    c = cluster_color_map('Set2')\n",
    "                if i == 2:\n",
    "                    c = cluster_color_map('Set1')\n",
    "                if i == 3:\n",
    "                    c = cluster_color_map('Pastel1')\n",
    "                row_cols = dict(zip(np.unique([j for j in htdata2.index.get_level_values(i)]), c))\n",
    "                row_color = pd.Series([j for j in htdata2.index.get_level_values(i)]).map(row_cols)\n",
    "                row_color.name = obs_cat[i]\n",
    "                row_colors.append(row_color)\n",
    "                row_colors_dict.update(row_cols)\n",
    "    else:\n",
    "        c = cluster_color_map('Accent')\n",
    "        row_color = dict(zip(np.unique([j for j in htdata2.index]), c))\n",
    "        row_colors = pd.Series([j for j in htdata2.index]).map(row_color)\n",
    "        row_colors_dict = row_color\n",
    "        row_colors.name = obs_cat[0]\n",
    "\n",
    "    if htdata2.columns.nlevels > 1:\n",
    "        for i in range(0,len(htdata2.columns[0])):       \n",
    "                # color first category\n",
    "                if i == 1:\n",
    "                    c = cluster_color_map('all')\n",
    "                if i == 0:\n",
    "                    c = cluster_color_map('Dark2')\n",
    "                cat_cols = dict(zip(np.unique([j for j in htdata2.columns.get_level_values(i)]), c))\n",
    "                col_color = pd.Series([j for j in htdata2.columns.get_level_values(i)]).map(cat_cols)\n",
    "                if i == 1:\n",
    "                    col_color.name = 'annotation'\n",
    "                else:\n",
    "                    col_color.name = 'Genes'\n",
    "                columns_colors.append(col_color)\n",
    "                cat_cols_dict.update(cat_cols)\n",
    "    else:\n",
    "        c = cluster_color_map('Dark2')\n",
    "        cat_cols = dict(zip(np.unique([j for j in htdata2.columns]), c))\n",
    "        columns_colors = pd.Series([j for j in htdata2.columns]).map(cat_cols)\n",
    "        cat_cols_dict = cat_cols\n",
    "        columns_colors.name = 'Genes'\n",
    "\n",
    "    if not isinstance(columns_colors, list): \n",
    "        columns_colors = [columns_colors]\n",
    "    if not isinstance(row_colors, list): \n",
    "        row_colors = [row_colors]\n",
    "\n",
    "    # gets final colors \n",
    "    rcol = pd.DataFrame(row_colors).T\n",
    "    rcol.index = htdata2.index\n",
    "    ccol = pd.DataFrame(columns_colors).T\n",
    "    ccol.index = htdata2.columns\n",
    "\n",
    "    # print(\"DE results for gene:\", gene)\n",
    "\n",
    "    # Plot heatmap\n",
    "    sns.set(font_scale=.45)\n",
    "    sns.set_style('ticks')\n",
    "\n",
    "    hb = sns.clustermap(htdata2,row_cluster=False, vmin = 0, row_colors = rcol, col_colors = ccol,\n",
    "                        col_cluster=False, cmap = 'magma', linewidth = 0.05, \n",
    "                        linecolor = 'black', cbar_kws={'label': u'lambda', 'pad':0})\n",
    "    plt.setp(hb.ax_heatmap.get_yticklabels(), rotation=0, ha=\"left\",\n",
    "         rotation_mode=\"anchor\")\n",
    "    hb.ax_heatmap.set_xlabel('')\n",
    "    hb.ax_heatmap.set_ylabel('')\n",
    "    handles = [Patch(facecolor={**cat_cols_dict, **row_colors_dict}[name]) for name in {**cat_cols_dict, **row_colors_dict}]\n",
    "    plt.legend(handles, {**cat_cols_dict, **row_colors_dict}, title='color annotations',\n",
    "               bbox_to_anchor=(0, 1), bbox_transform=plt.gcf().transFigure, loc='upper right')\n",
    "\n",
    "    return hb\n",
    "\n",
    "#Define cluster score for individual genes\n",
    "def marker_gene_expression(anndata, marker_dict, gene_symbol_key=None, partition_key='louvain_r1'):\n",
    "    \"\"\"\n",
    "    A function to get mean z-score expressions of marker genes\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    anndata         - An AnnData object containing the data set and a partition\n",
    "    #    marker_dict     - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or \n",
    "    #                      an anndata.var field with the key given by the gene_symbol_key input\n",
    "    #    gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker \n",
    "    #                      genes\n",
    "    #    partition_key   - The key for the anndata.obs field where the cluster IDs are stored. The default is\n",
    "    #                      'louvain_r1' \n",
    "    \"\"\"\n",
    "\n",
    "    #Test inputs\n",
    "    if partition_key not in anndata.obs.columns.values:\n",
    "        print('KeyError: The partition key was not found in the passed AnnData object.')\n",
    "        print('   Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!')\n",
    "        raise\n",
    "\n",
    "    if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):\n",
    "        print('KeyError: The provided gene symbol key was not found in the passed AnnData object.')\n",
    "        print('   Check that your cell type markers are given in a format that your anndata object knows!')\n",
    "        raise\n",
    "        \n",
    "    if gene_symbol_key:\n",
    "        gene_ids = anndata.var[gene_symbol_key]\n",
    "    else:\n",
    "        gene_ids = anndata.var_names\n",
    "\n",
    "    clusters = anndata.obs[partition_key].cat.categories\n",
    "    n_clust = len(clusters)\n",
    "    marker_exp = pd.DataFrame(columns=clusters)\n",
    "    marker_exp['cell_type'] = pd.Series({}, dtype='str')\n",
    "    marker_names = []\n",
    "    \n",
    "    z_scores = sc.pp.scale(anndata, copy=True)\n",
    "\n",
    "    i = 0\n",
    "    for group in marker_dict:\n",
    "        # Find the corresponding columns and get their mean expression in the cluster\n",
    "        for gene in marker_dict[group]:\n",
    "            ens_idx = np.in1d(gene_ids, gene) #Note there may be multiple mappings\n",
    "            if np.sum(ens_idx) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                z_scores.obs[ens_idx[0]] = z_scores.X[:,ens_idx].mean(1) #works for both single and multiple mapping\n",
    "                ens_idx = ens_idx[0]\n",
    "\n",
    "            clust_marker_exp = z_scores.obs.groupby(partition_key)[ens_idx].apply(np.mean).tolist()\n",
    "            clust_marker_exp.append(group)\n",
    "            marker_exp.loc[i] = clust_marker_exp\n",
    "            marker_names.append(gene)\n",
    "            i+=1\n",
    "\n",
    "    #Replace the rownames with informative gene symbols\n",
    "    marker_exp.index = marker_names\n",
    "\n",
    "    return(marker_exp)\n",
    "\n",
    "def splotch2anndata(ST_top_gene_dict, a, mode):\n",
    "    \"\"\"\n",
    "    A function to add DE genes as ranked genes to scanpy anndata object\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    a                  - An AnnData object containing the data set and a partition:conditions and annotation\n",
    "    #    ST_top_gene_dict   - A pd.DataFrame with fields: age_1, age_2, region_1, region_2, AAR1, AAR2, logsBFs (list), Delta (list), genes (list)  \n",
    "    #    mode               - A string denotype type of analysis to be collected: annotation_analysis,genotype_analysis,temporal_analysis\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### Add DE genes as ranked genes to scanpy anndata object\n",
    "\n",
    "    # make sure something to merge on\n",
    "    ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "    # filters ST_top for 'Annotation analysis'\n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] == 'Rest')]\n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'Rest')]\n",
    "    if mode == 'temporal_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'Rest')]\n",
    "    ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes']]\n",
    "    ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['annotation'], keep='first').reset_index(drop=True)\n",
    "\n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "    rank_genes_groups['names'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['names'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['logfoldchanges'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['pvals'] = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = ann_pd_merged['annotation']).T.to_records(column_dtypes='O',index=False)\n",
    "\n",
    "    # creates markers dict\n",
    "    tmp = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = ann_pd_merged['annotation'])\n",
    "    markers_dict_annotation_analysis = {}\n",
    "    for i,j in enumerate(tmp.index):\n",
    "        y = tmp.iloc[i,:]\n",
    "        markers_dict_annotation_analysis[j] = [x for x in y if str(x) != 'nan']\n",
    "\n",
    "    \n",
    "    # makes zscores\n",
    "    marker_gene_expressions = marker_gene_expression(a, markers_dict_annotation_analysis, gene_symbol_key=None, partition_key='annotation')\n",
    "    marker_gene_expressions = marker_gene_expressions.drop(labels='cell_type', axis=1).to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['scores'] = marker_gene_expressions\n",
    "    \n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    #atest = a.copy()\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "    \n",
    "def splotch2anndata_v3(ST_top_gene_dict, a, mode, conditions_order = None):\n",
    "    \n",
    "    #ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    #a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "\n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "\n",
    "    # filters ST_top for 'Annotation analysis'\n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] == 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['AAR1'], right_on = ['annotation'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1', 'region_1', 'AAR1']]\n",
    "        ann_pd_merged['dups'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['annotation'])  \n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['annotation'].isin(conditions_order)]\n",
    "               \n",
    "        \n",
    "        #inx_name = [i+'_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'])]\n",
    "        inx_name = [i for i in ann_pd_merged['annotation']]\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "        #ann_pd_merged['age1_region1'] = [i+\"_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'])]\n",
    "        ann_pd_merged['age1_region1'] = [i for i in ann_pd_merged['annotation']]\n",
    "        means_pd_index = ann_pd_merged.groupby('age1_region1')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        #for cond in means_pd_index['age1_region1']:\n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(inx_name):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            sub = means_pd_index[means_pd_index['age1_region1'] == cond]['index'].iloc[0]\n",
    "            asub = a[a.obs.index.isin(sub)]\n",
    "            asub = asub[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            #asub = asub[:,rank_genes_groups['names'][cond]]\n",
    "            asub.obs['merging'] = cond\n",
    "            asub.var_names_make_unique()\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] != ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['region_1'], right_on = ['Region'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        ann_pd_merged['region1_region2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['region1_region2'])\n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['region1_region2'].isin(conditions_order)]\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "        \n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        means_pd_index = ann_pd_merged.groupby('region1_region2')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        #for cond in means_pd_index['region1_region2']:\n",
    "        #    cond_names.append(cond)\n",
    "        \n",
    "        #ann_pd_merged['index'] = inx_name   \n",
    "        for cond in conditions_order:\n",
    "            if not cond in list(inx_name):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            sub = means_pd_index[means_pd_index['region1_region2'] == cond]['index'].iloc[0]\n",
    "            asub = a[a.obs.index.isin(sub)]\n",
    "            asub = asub[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            #asub = asub[:,rank_genes_groups['names'][cond]]\n",
    "            asub.obs['merging'] = cond\n",
    "            asub.var_names_make_unique()\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    if mode == 'temporal_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        #ann_pd['age1_age2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd['age_1'], ann_pd['age_2'])]\n",
    "        #print(np.unique(ann_pd['age1_age2']))\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['age_1'], right_on = ['Age'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','age_2', 'region_1']]\n",
    "        #ann_pd_merged['age1_age2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #print(np.unique(ann_pd_merged['age1_age2']))\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        \n",
    "        ann_pd_merged['age1_age2'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #print(np.unique(ann_pd_merged['age1_age2']))\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['age1_age2'])\n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['age1_age2'].isin(conditions_order)]\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #ann_pd_merged['index'] = inx_name \n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        means_pd_index = ann_pd_merged.groupby('age1_age2')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        #for cond in means_pd_index['age1_age2']:\n",
    "        #    cond_names.append(cond)\n",
    "            \n",
    "           \n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(inx_name):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            sub = means_pd_index[means_pd_index['age1_age2'] == cond]['index'].iloc[0]\n",
    "            asub = a[a.obs.index.isin(sub)]\n",
    "            asub = asub[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            #asub = asub[:,rank_genes_groups['names'][cond]]\n",
    "            asub.obs['merging'] = cond\n",
    "            asub.var_names_make_unique()\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "\n",
    "\n",
    "def splotch2anndata_v2(ST_top_gene_dict, a, mode):\n",
    "    \"\"\"\n",
    "    A function to add DE genes as ranked genes to scanpy anndata object\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    a                  - An AnnData object containing the data set and a partition:conditions and annotation\n",
    "    #    ST_top_gene_dict   - A pd.DataFrame with fields: age_1, age_2, region_1, region_2, AAR1, AAR2, logsBFs (list), Delta (list), genes (list)  \n",
    "    #    mode               - A string denotype type of analysis to be collected: annotation_analysis,genotype_analysis,temporal_analysis\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "    # filters ST_top for 'Annotation analysis'\n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] == 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes','age_1', 'region_1', 'AAR1']]\n",
    "        ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        inx_name = [i+'_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'])]\n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] != ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "    if mode == 'temporal_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['annotation', 'logBFs', 'Delta','genes','age_1','age_2', 'region_1']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        inx_name = [i+'_vs_'+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        \n",
    "        \n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "    #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "    rank_genes_groups['names'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "    rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "    # creates markers dict\n",
    "    tmp_genes = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)\n",
    "    tmp_bfs = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['logBFs']], index = inx_name)\n",
    "    tmp_deltas = pd.DataFrame([pd.Series(i) for i in ann_pd_merged['Delta']], index = inx_name)\n",
    "    markers_dict_annotation_analysis = {}\n",
    "    bfs_dict_annotation_analysis = {}\n",
    "    deltas_dict_annotation_analysis = {}\n",
    "    for i,j in enumerate(tmp_genes.index):\n",
    "        y = tmp_genes.iloc[i,:]\n",
    "        k = tmp_bfs.iloc[i,:]\n",
    "        l = tmp_deltas.iloc[i,:]\n",
    "        markers_dict_annotation_analysis[j] = [x for x in y if str(x) != 'nan']\n",
    "        bfs_dict_annotation_analysis[j] = [x for x in k if str(x) != 'nan']\n",
    "        deltas_dict_annotation_analysis[j] = [x for x in l if str(x) != 'nan']\n",
    "\n",
    "    # makes zscores\n",
    "    marker_gene_expressions = marker_gene_expression(a, markers_dict_annotation_analysis, gene_symbol_key=None, partition_key='annotation')\n",
    "    marker_gene_expressions = marker_gene_expressions.drop(labels='cell_type', axis=1).to_records(column_dtypes='O',index=False)\n",
    "    rank_genes_groups['scores'] = marker_gene_expressions\n",
    "\n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "    \n",
    "    \n",
    "    \n",
    "    a.obs['index'] = a.obs.index\n",
    "\n",
    "def splotch2anndata_v4(ST_top_gene_dict, a, mode, conditions_order = None):    \n",
    "\n",
    "    ST_top_gene_dict['final_conditions'] = [i+\"_\"+j+\"_\"+k for i,j,k in zip(ST_top_gene_dict['region_1'], ST_top_gene_dict['age_1'], ST_top_gene_dict['AAR1'])]\n",
    "    a.obs['final_conditions'] = [i+\"_\"+j for i,j in zip(a.obs['conditions'], a.obs['annotation'])]\n",
    "\n",
    "    # creates ranked genes object\n",
    "    rank_genes_groups = dict()\n",
    "    rank_genes_groups['params'] = dict(groupby = 'annotation',\n",
    "                                       reference = 'rest',\n",
    "                                       method = mode,\n",
    "                                       use_raw = False,\n",
    "                                       layer = None,)\n",
    "\n",
    "    if mode == 'temporal_analysis':\n",
    "        \n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['age_1'], right_on = ['Age'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','age_2', 'region_1']]\n",
    "        #ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['region_1'], ann_pd_merged['age_1'], ann_pd_merged['age_2'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        ann_pd_merged['age'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['age_1'], ann_pd_merged['age_2'])]\n",
    "        #ann_pd_merged['age'] = [i for i in ann_pd_merged['age_1']]\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['age'])\n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['age'].isin(conditions_order)]\n",
    "        #print(np.unique(ann_pd_merged.age))\n",
    "\n",
    "        #makes sure unique gene names per group\n",
    "        tmp = ann_pd_merged.groupby(\"age\").sum()\n",
    "        tmp = tmp.replace(to_replace='None', value=np.nan).dropna()\n",
    "        ann_pd_merged_tmp = pd.DataFrame(columns = ['genes', 'Delta', 'logBFs'])\n",
    "        for i,j in enumerate(tmp.index):\n",
    "            gn_inx = list(np.unique(list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            bfs_ind = np.argsort(np.array([list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]]))[::-1]\n",
    "            ann_pd_merged_tmp.at[i,'genes'] = [[list(tmp.iloc[i,:]['genes'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'Delta'] = [[list(tmp.iloc[i,:]['Delta'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'logBFs'] = [[list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "        ann_pd_merged_tmp['age'] = tmp.index\n",
    "        inx_name = ann_pd_merged_tmp['age']\n",
    "\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        #means_pd_index = ann_pd_merged_tmp.groupby('age')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        for cond in conditions_order:\n",
    "            if not cond in list(ann_pd_merged_tmp['age']):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            asub = a[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            asub.obs['merging'] = cond\n",
    "            sc.pp.scale(asub, max_value=10)\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "        \n",
    "    if mode == 'genotype_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['age_1'] == ST_top_gene_dict['age_2']) & (ST_top_gene_dict['region_1'] != ST_top_gene_dict['region_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k+l for i,j,k,l in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'], ann_pd_merged['annotation'])]\n",
    "        #ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['region_2'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        ann_pd_merged['region'] = [i+\"_vs_\"+j for i,j in zip(ann_pd_merged['region_1'],ann_pd_merged['region_2'])]\n",
    "        #ann_pd_merged['region'] = [i for i in ann_pd_merged['region_1']]\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['region'])\n",
    "        \n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['region'].isin(conditions_order)]\n",
    "\n",
    "        #makes sure unique gene names per group\n",
    "        tmp = ann_pd_merged.groupby(\"region\").sum()\n",
    "        tmp = tmp.replace(to_replace='None', value=np.nan).dropna()\n",
    "        ann_pd_merged_tmp = pd.DataFrame(columns = ['genes', 'Delta', 'logBFs'])\n",
    "        for i,j in enumerate(tmp.index):\n",
    "            gn_inx = list(np.unique(list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            bfs_ind = np.argsort(np.array([list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]]))[::-1]\n",
    "            ann_pd_merged_tmp.at[i,'genes'] = [[list(tmp.iloc[i,:]['genes'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'Delta'] = [[list(tmp.iloc[i,:]['Delta'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'logBFs'] = [[list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "        ann_pd_merged_tmp['region'] = tmp.index\n",
    "        inx_name = ann_pd_merged_tmp['region']\n",
    "\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        #means_pd_index = ann_pd_merged_tmp.groupby('age')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(ann_pd_merged_tmp['region']):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            asub = a[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            asub.obs['merging'] = cond\n",
    "            sc.pp.scale(asub, max_value=10)\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)        \n",
    "        \n",
    "    if mode == 'annotation_analysis':\n",
    "        ann_pd = ST_top_gene_dict[(ST_top_gene_dict['region_1'] == ST_top_gene_dict['region_2']) & (ST_top_gene_dict['age_1'] != ST_top_gene_dict['age_2']) & (ST_top_gene_dict['AAR2'] != 'rest')]\n",
    "        ann_pd_merged = pd.merge(ann_pd, a.obs, left_on = ['final_conditions'], right_on = ['final_conditions'])[['index', 'annotation', 'logBFs', 'Delta','genes','age_1','region_1', 'region_2']]\n",
    "        ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'],  ann_pd_merged['annotation'])]\n",
    "        #ann_pd_merged['dups'] = [i+j+k for i,j,k in zip(ann_pd_merged['age_1'], ann_pd_merged['region_1'], ann_pd_merged['annotation'])]\n",
    "        ann_pd_merged = ann_pd_merged.drop_duplicates(subset=['dups'], keep='first').reset_index(drop=True)\n",
    "        if conditions_order == None: \n",
    "            conditions_order = np.unique(ann_pd_merged['annotation'])  \n",
    "        ann_pd_merged = ann_pd_merged[ann_pd_merged['annotation'].isin(conditions_order)]\n",
    "\n",
    "        #makes sure unique gene names per group\n",
    "        tmp = ann_pd_merged.groupby(\"annotation\").sum()\n",
    "        tmp = tmp.replace(to_replace='None', value=np.nan).dropna()\n",
    "        ann_pd_merged_tmp = pd.DataFrame(columns = ['genes', 'Delta', 'logBFs'])\n",
    "        for i,j in enumerate(tmp.index):\n",
    "            gn_inx = list(np.unique(list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            #gn_inx = list((list(tmp.iloc[i,:]['genes']),return_index=True))\n",
    "            bfs_ind = np.argsort(np.array([list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]]))[::-1]\n",
    "            ann_pd_merged_tmp.at[i,'genes'] = [[list(tmp.iloc[i,:]['genes'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'Delta'] = [[list(tmp.iloc[i,:]['Delta'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "            ann_pd_merged_tmp.at[i,'logBFs'] = [[list(tmp.iloc[i,:]['logBFs'])[j] for j in gn_inx[1]][k] for k in bfs_ind]\n",
    "        ann_pd_merged_tmp['annotation'] = tmp.index\n",
    "        inx_name = ann_pd_merged_tmp['annotation']\n",
    "\n",
    "        #rank_genes_groups['names'] = np.unique(pd.concat([pd.DataFrame([pd.Series(i) for i in ann_pd_merged['genes']], index = inx_name)]).astype(str).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False))\n",
    "        rank_genes_groups['names'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['genes']], index = inx_name)]).groupby(level=0).first().T.replace('nan', '').to_records(column_dtypes='O',index=False)\n",
    "        rank_genes_groups['logfoldchanges'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['Delta']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float32',index=False)\n",
    "        rank_genes_groups['pvals'] = pd.concat([pd.DataFrame([(pd.Series(i)) for i in ann_pd_merged_tmp['logBFs']], index = inx_name)]).groupby(level=0).first().T.to_records(column_dtypes='float64',index=False)\n",
    "\n",
    "        #means_pd_index = ann_pd_merged_tmp.groupby('age')['index'].apply(list).reset_index()\n",
    "        marker_gene_means = []\n",
    "        cond_names = []\n",
    "        for cond in np.array(conditions_order):\n",
    "            if not cond in list(ann_pd_merged_tmp['annotation']):\n",
    "                continue\n",
    "            cond_names.append(cond)\n",
    "            asub = a[:,[x for x in rank_genes_groups['names'][cond] if str(x) != 'nan']]\n",
    "            asub.obs['merging'] = cond\n",
    "            sc.pp.scale(asub, max_value=10)\n",
    "            marker_gene_means.append(list(grouped_obs_mean(asub, group_key = 'merging').reindex(rank_genes_groups['names'][cond])[cond]))\n",
    "        rank_genes_groups['scores'] = pd.DataFrame(marker_gene_means, index = cond_names).T.to_records(column_dtypes='float32',index=False)\n",
    "\n",
    "    #return a new anndata object\n",
    "    print(mode)\n",
    "    a.uns[mode] = rank_genes_groups\n",
    "\n",
    "def filter_rank_genes_groups(\n",
    "    adata,\n",
    "    key=None,\n",
    "    key_added='rank_genes_groups_filtered',\n",
    "    min_fold_change=0,\n",
    "    min_pvals_change=0.5,\n",
    "    min_scores=0\n",
    ") -> None:\n",
    "\n",
    "    if key is None:\n",
    "        key = 'rank_genes_groups'\n",
    "\n",
    "    # convert structured numpy array into DataFrame\n",
    "    gene_names = pd.DataFrame(adata.uns[key]['names'])\n",
    "    \n",
    "    #gets unique names\n",
    "    genes_new = pd.DataFrame(columns = gene_names.columns)\n",
    "    for cond, ind in enumerate(gene_names):\n",
    "        genes_tmp = []\n",
    "        for i in range(0,len(gene_names[ind])):\n",
    "            if str(gene_names[ind][i]) in genes_tmp:\n",
    "                genes_new.at[i, ind] = np.nan\n",
    "            else:\n",
    "                if gene_names[ind][i] == 'nan':\n",
    "                    gene_names[ind][i] = np.nan\n",
    "                genes_new.at[i, ind] = gene_names[ind][i]\n",
    "            genes_tmp.append(gene_names[ind][i])\n",
    "    gene_names = genes_new    \n",
    "\n",
    "    fold_change_matrix = pd.DataFrame(adata.uns[key]['logfoldchanges'])\n",
    "    pvals_change_matrix = pd.DataFrame(adata.uns[key]['pvals'])\n",
    "    scores_change_matrix = pd.DataFrame(adata.uns[key]['scores'])\n",
    "    \n",
    "    # filter original_matrix\n",
    "    gene_names = gene_names[(fold_change_matrix >= min_fold_change)]\n",
    "    gene_names = gene_names[(pvals_change_matrix >= min_pvals_change)]\n",
    "    gene_names = gene_names[(scores_change_matrix >= min_scores)]\n",
    "    fold_change_matrix = fold_change_matrix[(fold_change_matrix >= min_fold_change)]\n",
    "    pvals_change_matrix = pvals_change_matrix[(pvals_change_matrix >= min_pvals_change)]  \n",
    "    scores_change_matrix = scores_change_matrix[(scores_change_matrix >= min_scores)]\n",
    "    \n",
    "    # create new structured array using 'key_added'.\n",
    "    adata.uns[key_added] = adata.uns[key].copy()\n",
    "    adata.uns[key_added]['names'] = gene_names.to_records(index=False,column_dtypes='O')\n",
    "    adata.uns[key_added]['logfoldchanges'] = fold_change_matrix.to_records(index=False,column_dtypes='float32')\n",
    "    adata.uns[key_added]['pvals'] = pvals_change_matrix.to_records(index=False,column_dtypes='float64')\n",
    "    adata.uns[key_added]['pvals_adj'] = pvals_change_matrix.to_records(index=False,column_dtypes='float64')\n",
    "    adata.uns[key_added]['scores'] = scores_change_matrix.to_records(index=False,column_dtypes='float32')\n",
    "\n",
    "def filter_BFs(st_spec):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function that filters the BF files from cloud\n",
    "    # \n",
    "    # Inputs:\n",
    "    #    st_spec             - BF data frame\n",
    "    #    ST_top_gene_dict   - A pd.DataFrame with fields: age_1, age_2, region_1, region_2, AAR1, AAR2, logsBFs (list), Delta (list), genes (list)  \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    # do some renaming\n",
    "# st_spec = st_spec[st_spec['BF'] != inf]\n",
    "\n",
    "    # Log10 BF\n",
    "#     st_spec['BF'] = np.float64(st_spec['BF'])\n",
    "#     st_spec.BF[st_spec.BF == -inf] = sys.float_info.min # makes sure no inf\n",
    "#     st_spec.BF[st_spec.BF == inf] = sys.float_info.max # makes sure no inf\n",
    "#     st_spec['logBF'] = np.log(st_spec['BF'])\n",
    "\n",
    "    # rename gene names\n",
    "    st_spec['gene_new'] = [i.split(\"_\")[0] for i in st_spec['gene']]\n",
    "    st_spec['genotype_1'] = [i.split(\" \")[0] for i in st_spec['condition_1']]\n",
    "    st_spec['sex_1'] = [i.split(\" \")[1] for i in st_spec['condition_1']]\n",
    "    st_spec['genotype_2'] = [i.split(\" \")[0] for i in st_spec['condition_2']]\n",
    "    st_spec['sex_2'] = [i.split(\" \")[1] for i in st_spec['condition_2']]    \n",
    "    \n",
    "    ## Top 100 ST genes per condition and per region\n",
    "    ST_top_gene_dict = pd.DataFrame(columns = ['genotype_1', 'genotype_2', 'sex_1', 'sex_2', 'AAR1', 'AAR2', 'genes', 'logBFs', 'Delta'])\n",
    "    counter = 0\n",
    "    df_group = st_spec.groupby(['genotype_1', 'genotype_2', 'sex_1', 'sex_2', 'AAR1', 'AAR2'])\n",
    "    for label, dfs in df_group: # this is for splotch_one_level\n",
    "\n",
    "        # this gets genes super specific against the whole rest of the datset\n",
    "\n",
    "        #if (label[5] == 'Rest'):\n",
    "\n",
    "        #print(counter)\n",
    "\n",
    "        #dfs = df[(df['logBF'] > 2) & (df['Delta'] > 0)]\n",
    "        #dfs = dfs[(dfs['logBF'] > 0)& (dfs['Delta'] > 0)]\n",
    "        #dfs = df\n",
    "        #print(df.sort_values(by='logBF', ascending=False)['gene_new'].head(5).tolist())\n",
    "        if (len(dfs.sort_values(by='logBF', ascending=False)['gene_new'].head(5).tolist()) == 0):\n",
    "            continue\n",
    "\n",
    "        ST_top_gene_dict.at[counter, 'genotype_1'] = label[0]\n",
    "        ST_top_gene_dict.at[counter, 'genotype_2'] = label[1]\n",
    "        ST_top_gene_dict.at[counter, 'sex_1'] = label[2]\n",
    "        ST_top_gene_dict.at[counter, 'sex_2'] = label[3]\n",
    "        ST_top_gene_dict.at[counter, 'AAR1'] = label[4]\n",
    "        ST_top_gene_dict.at[counter, 'AAR2'] = label[5]\n",
    "        ST_top_gene_dict.at[counter, 'genes'] = dfs.sort_values(by=['logBF',], ascending=[False,])['gene_new'].tolist()[0:3999]\n",
    "        ST_top_gene_dict.at[counter, 'logBFs'] = dfs.sort_values(by=['logBF', ], ascending=[False,])['logBF'].tolist()[0:3999]\n",
    "        ST_top_gene_dict.at[counter, 'Delta'] = dfs.sort_values(by=['logBF', ], ascending=[False,])['Delta'].tolist()[0:3999]\n",
    "        counter += 1\n",
    "    print('done clean up')\n",
    "    return ST_top_gene_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads in tsv file and makes a dataframe for bacterial comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  1  out of:  35\n",
      "Reading chunk:  2  out of:  35\n",
      "Reading chunk:  3  out of:  35\n",
      "Reading chunk:  4  out of:  35\n",
      "Reading chunk:  5  out of:  35\n",
      "Reading chunk:  6  out of:  35\n",
      "Reading chunk:  7  out of:  35\n",
      "Reading chunk:  8  out of:  35\n",
      "Reading chunk:  9  out of:  35\n",
      "Reading chunk:  10  out of:  35\n",
      "Reading chunk:  11  out of:  35\n",
      "Reading chunk:  12  out of:  35\n",
      "Reading chunk:  13  out of:  35\n",
      "Reading chunk:  14  out of:  35\n",
      "Reading chunk:  15  out of:  35\n",
      "Reading chunk:  16  out of:  35\n",
      "Reading chunk:  17  out of:  35\n",
      "Reading chunk:  18  out of:  35\n",
      "Reading chunk:  19  out of:  35\n",
      "Reading chunk:  20  out of:  35\n",
      "Reading chunk:  21  out of:  35\n",
      "Reading chunk:  22  out of:  35\n",
      "Reading chunk:  23  out of:  35\n",
      "Reading chunk:  24  out of:  35\n",
      "Reading chunk:  25  out of:  35\n",
      "Reading chunk:  26  out of:  35\n",
      "Reading chunk:  27  out of:  35\n",
      "Reading chunk:  28  out of:  35\n",
      "Reading chunk:  29  out of:  35\n",
      "Reading chunk:  30  out of:  35\n",
      "Reading chunk:  31  out of:  35\n",
      "Reading chunk:  32  out of:  35\n",
      "Reading chunk:  33  out of:  35\n",
      "Reading chunk:  34  out of:  35\n",
      "Reading chunk:  35  out of:  35\n"
     ]
    }
   ],
   "source": [
    "# Load ST files  \n",
    "path = '/home/sanjavickovic/data/host-microbiome_data/splotch_outputs/wt_gf_zeros/'\n",
    "\n",
    "# Read file\n",
    "filename = os.path.join(path, 'BF.tsv.gz')\n",
    "\n",
    "# makes initial pd\n",
    "fields = ['gene', 'condition_1', 'condition_2', 'AAR1', 'AAR2', 'BF', 'Delta']\n",
    "# reader = pd.read_csv(filename, sep='\\t', chunksize=int(100000), engine='python', skipinitialspace=True, usecols=fields)    \n",
    "\n",
    "# # makes small pkl files\n",
    "# for i, chunk in enumerate(reader):\n",
    "#     out_file = path + \"data_subset_{}.pkl\".format(i+1)\n",
    "#     print(\"Processing chunk: \", i+1)\n",
    "#     with open(out_file, \"wb\") as f:\n",
    "#         pickle.dump(chunk,f,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# arranges pkl files into a df\n",
    "data_p_files=[]\n",
    "for name in glob.glob(path + \"data_subset_*.pkl\"):\n",
    "       data_p_files.append(name)\n",
    "df_bf = pd.DataFrame([])\n",
    "for i in range(len(data_p_files)):\n",
    "    #if i % 20 == 0:\n",
    "    print(\"Reading chunk: \", i+1, ' out of: ', len(data_p_files))\n",
    "    tmp = pd.read_pickle(data_p_files[i])\n",
    "    tmp = tmp[tmp['gene'] != 'gene']    \n",
    "    tmp['BF'] = tmp['BF'].astype(float)\n",
    "    tmp['Delta'] = tmp['Delta'].astype(float)\n",
    "    tmp = tmp[(tmp['BF']>0) & (tmp['Delta']>0)]\n",
    "    df_bf = df_bf.append(tmp,ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Subset anndata and ST_dict to same genes'\n",
    "'Read in large anndata'\n",
    "a = sc.read_h5ad('/home/sanjavickovic/data/host-microbiome_data/st_data/anndata_hm_norm_all_Feb2022.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Add WT bacterial lambdas in place'\n",
    "def rename_lambdas_index(lambdas_file): \n",
    "    nwe=[]\n",
    "    nm=lambdas_file.index\n",
    "    for item in nm:\n",
    "        nwe.append(str(item).split(\"_\")[0])\n",
    "    return nwe\n",
    "\n",
    "# Load Lambda pmean df as from gcp\n",
    "path = '/home/sanjavickovic/data/host-microbiome_data/splotch_outputs/wt_gf_zeros'\n",
    "\n",
    "# Read expression file\n",
    "filename = os.path.join(path, 'lambdas_python.tsv.gz')  \n",
    "lambda_posterior_means = pd.read_csv(filename, index_col=0, low_memory=False, header=[0,1], sep=',') \n",
    "\n",
    "#rename genes\n",
    "lambda_posterior_means.index = rename_lambdas_index(lambda_posterior_means)\n",
    "\n",
    "#rename columns \n",
    "count_files = lambda_posterior_means.columns.map('_'.join).str.strip('_')\n",
    "count_files_names = [i.split(\"/\")[-1].replace(\"_stdata_adjusted.tsv\", \"\") for i in count_files]\n",
    "lambda_posterior_means.columns = count_files_names\n",
    "\n",
    "# Take exp()\n",
    "lambda_posterior_means = lambda_posterior_means.astype(float)\n",
    "lambda_posterior_means = np.exp(lambda_posterior_means-1)\n",
    "\n",
    "#prep lamdas\n",
    "lambda_posterior_means_t = lambda_posterior_means.T\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.loc[:,~lambda_posterior_means_t.columns.str.startswith('coordinate')]\n",
    "\n",
    "# subset to bacteria only\n",
    "#lambda_posterior_means_t = lambda_posterior_means_t[[i for i in lambda_posterior_means_t.columns if i.endswith(\"Bacteria\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subset to GF\"\n",
    "# a_gf = a[~a.obs.index.isin(lambda_posterior_means_t.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subset to WT\"\n",
    "# a_wt = a[a.obs.index.isin(lambda_posterior_means_t.index)]\n",
    "# lambda_posterior_means_t = lambda_posterior_means_t.reindex(a_wt.obs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subset WT to bac vs. genes\"\n",
    "# a_wt_bac = a_wt[:,a_wt.var_names.isin(lambda_posterior_means_t.columns)]\n",
    "# a_wt_bac.X = lambda_posterior_means_t.values\n",
    "# a_wt_genes = a_wt[:,~a_wt.var_names.isin(lambda_posterior_means_t.columns)]\n",
    "# a_wt_n = a_wt.copy()\n",
    "# a_wt_n.X = np.concatenate((a_wt_genes.X, a_wt_bac.X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Make new anndata\"\n",
    "# a_n = a_wt_n.concatenate(a_gf)\n",
    "# a_n.obs.drop([\"batch\", \"Gnai3\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Put in new lambdas with exhisting observations'\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.reindex(a.obs.index)\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.dropna()\n",
    "lambda_posterior_means_t = lambda_posterior_means_t.loc[:,~lambda_posterior_means_t.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = a.obs.loc[lambda_posterior_means_t.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puts in new lambdas into \n",
    "a_n = anndata.AnnData(X = lambda_posterior_means_t.values, obs = obs)\n",
    "a_n.var_names = lambda_posterior_means_t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two extra bacteria\n",
    "#a_n = a_n[:,a_n.var_names.isin([i for i in a_n.var_names if 'Lacrimispora' not in i])]\n",
    "#a_n = a_n[:,a_n.var_names.isin([i for i in a_n.var_names if 'Acetobacterium' not in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Adds bacterial to genes expression lambdas'\n",
    "a_n.write_h5ad(filename = '/home/sanjavickovic/data/host-microbiome_data/st_data/anndata_hm_norm_all_n_Feb2022.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Filter to get only bacteria'\n",
    "df_bf['gene_new'] = [i.split(\"_\")[0] for i in df_bf.gene]\n",
    "#df_bf = df_bf.loc[[i[0] for i in enumerate(df_bf.gene_new) if i[1] in a.var_names]]\n",
    "#df_bf.reset_index(inplace = True)\n",
    "# df_bf.condition_1 = 'WT F'\n",
    "# df_bf.condition_2 = 'WT F'\n",
    "\n",
    "'This are the wt bacterial comparisons'\n",
    "tmp = df_bf[(df_bf.AAR2 == 'Rest')&(df_bf.condition_1 == df_bf.condition_2) &(df_bf.condition_1 == 'WT F')]\n",
    "tmp_bac = tmp[tmp.gene.isin([i for i in tmp.gene if \"Bacteria\" in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two additional bacteria\n",
    "tmp_bac = tmp_bac[tmp_bac.gene.isin([i for i in tmp_bac.gene if \"Lacrimispora\" not in i])]\n",
    "tmp_bac = tmp_bac[tmp_bac.gene.isin([i for i in tmp_bac.gene if \"Acetobacterium\" not in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_wt_vs_gf = df_bf[(df_bf.condition_1 == 'WT F') & ((df_bf.condition_2 == 'GF F') | (df_bf.condition_2 == 'GF M')) & (df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i]))]\n",
    "tmp_gf_vs_wt = df_bf[((df_bf.condition_1 == 'GF F') | (df_bf.condition_1 == 'GF M')) & (df_bf.condition_2 == 'WT F') & (df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two additional bacteria\n",
    "tmp_wt_vs_gf = tmp_wt_vs_gf[tmp_wt_vs_gf.gene.isin([i for i in tmp_wt_vs_gf.gene if \"Lacrimispora\" not in i])]\n",
    "tmp_wt_vs_gf = tmp_wt_vs_gf[tmp_wt_vs_gf.gene.isin([i for i in tmp_wt_vs_gf.gene if \"Acetobacterium\" not in i])]\n",
    "tmp_gf_vs_wt = tmp_gf_vs_wt[tmp_gf_vs_wt.gene.isin([i for i in tmp_gf_vs_wt.gene if \"Acetobacterium\" not in i])]\n",
    "tmp_gf_vs_wt = tmp_gf_vs_wt[tmp_gf_vs_wt.gene.isin([i for i in tmp_gf_vs_wt.gene if \"Lacrimispora\" not in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_wt1 = df_bf[~df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads in tsv file and makes a dataframe for wt vs gf gene comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load ST files  \n",
    "# path = '/home/brittalotstedt/host-microbiome/data/bfs/'\n",
    "\n",
    "# # Read file\n",
    "# filename = os.path.join(path, 'BF.tsv.gz')\n",
    "\n",
    "# # makes initial pd\n",
    "# fields = ['gene', 'condition_1', 'condition_2', 'AAR1', 'AAR2', 'BF', 'Delta']\n",
    "# # reader = pd.read_csv(filename, sep='\\t', chunksize=int(2000000), engine='python', skipinitialspace=True, usecols=fields)    \n",
    "\n",
    "# # # makes small pkl files\n",
    "# # for i, chunk in enumerate(reader):\n",
    "# #     out_file = path + \"data_subset_{}.pkl\".format(i+1)\n",
    "# #     print(\"Processing chunk: \", i+1)\n",
    "# #     with open(out_file, \"wb\") as f:\n",
    "# #         pickle.dump(chunk,f,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # arranges pkl files into a df\n",
    "# data_p_files=[]\n",
    "# for name in glob.glob(path + \"data_subset*.pkl\"):\n",
    "#        data_p_files.append(name)\n",
    "# df_bf = pd.DataFrame([])\n",
    "# for i in range(len(data_p_files)):\n",
    "#     #if i % 20 == 0:\n",
    "#     print(\"Reading chunk: \", i+1, ' out of: ', len(data_p_files))\n",
    "#     tmp = pd.read_pickle(data_p_files[i])\n",
    "#     tmp = tmp[tmp['gene'] != 'gene']    \n",
    "#     tmp['BF'] = tmp['BF'].astype(float)\n",
    "#     tmp['Delta'] = tmp['Delta'].astype(float)\n",
    "#     tmp = tmp[(tmp['BF']>0) & (tmp['Delta']>0)]\n",
    "#     df_bf = df_bf.append(tmp,ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Remove bacterial comparisons from df file'\n",
    "# df_bf['gene_new'] = [i.split(\"_\")[0] for i in df_bf.gene]\n",
    "# #tmp_wt_vs_gf = df_bf[(df_bf.condition_1 == 'WT F') & ((df_bf.condition_2 == 'GF F') | (df_bf.condition_2 == 'GF M')) & (df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i]))]\n",
    "# tmp_wt = df_bf[~df_bf.gene.isin([i for i in df_bf.gene if \"Bacteria\" in i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bf_combined = pd.concat([tmp_bac, tmp_wt1, tmp_wt_vs_gf, tmp_gf_vs_wt])\n",
    "df_bf_combined.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/sanjavickovic/miniconda3/envs/stenv3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_bf_combined.BF = np.float64(df_bf_combined.BF)\n",
    "df_bf_combined.BF[df_bf_combined.BF == -inf] = sys.float_info.min # makes sure no inf\n",
    "df_bf_combined.BF[df_bf_combined.BF == inf] = sys.float_info.max # makes sure no inf\n",
    "df_bf_combined['logBF'] = np.log(df_bf_combined.BF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done clean up\n"
     ]
    }
   ],
   "source": [
    "ST_top_gene_dict = filter_BFs(df_bf_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genotype_1</th>\n",
       "      <th>genotype_2</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>AAR1</th>\n",
       "      <th>AAR2</th>\n",
       "      <th>genes</th>\n",
       "      <th>logBFs</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt apex and crypt mid</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Plac8, Slco6c1, Uckl1, Gm12367, Tspear, Mtmr1...</td>\n",
       "      <td>[2.0122117282095053, 1.542921882516165, 1.4583...</td>\n",
       "      <td>[0.65223562354725, 3.8131681028384583, 1.25715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt apex and mucosa</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Mtmr11, Gm32200, Scd4, Cyp2d34, Gimd1, Lyzl4o...</td>\n",
       "      <td>[0.28519925093975473, 0.029994950489092207, -0...</td>\n",
       "      <td>[0.6372250459891668, 1.2219540229105, 0.415214...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt base</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Bpifc, Mapre3, Usp9y, Dydc1, Gm4955, Gm15655,...</td>\n",
       "      <td>[1.0082060694559545, 0.8305594259474725, 0.734...</td>\n",
       "      <td>[2.5167639623125004, 1.8401814456808336, 2.079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>crypt mid</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Ydjc, Aknad1, Stard4, Rnf4, Phb, Ctc1, Smim4,...</td>\n",
       "      <td>[3.4466429431031056, 2.533555270712622, 1.4905...</td>\n",
       "      <td>[1.937673891208333, 4.860282585321833, 0.70985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GF</td>\n",
       "      <td>GF</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>epithelium</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Fgf23, Igkv8-31, Npr1, Gm43705, Tnfsf11, Clec...</td>\n",
       "      <td>[0.21825720536127427, -0.06046643125800337, -0...</td>\n",
       "      <td>[0.05216546580691617, 0.7135883506803333, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>mucosa and pellet</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Saa1, Lypd8, Car4, Abcb1a, Sepp1, Hist1h1c, P...</td>\n",
       "      <td>[3.5810409565550567, 1.1435238760455382, 1.131...</td>\n",
       "      <td>[1.142071956405275, 0.5003454392266667, 0.8313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>mucosae and interna</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[P4ha1, Mylk3, Gm3985, Dhx32, Tmem45a, Nog, Gm...</td>\n",
       "      <td>[1.30868985066532, 1.2956374600132459, 1.14272...</td>\n",
       "      <td>[1.1789173022458332, 2.065658233677333, 2.0385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>muscle and submucosa</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Cd2, Lrp8os3, Cyp4a10, Oas1g, Gm38073, 493057...</td>\n",
       "      <td>[0.2730773858106193, 0.17285301481707396, 0.16...</td>\n",
       "      <td>[1.7318922431808335, 0.30870173119785826, 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>pellet</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[Clca1, Rbm47, Slc26a3, Saa1, Massilistercora-...</td>\n",
       "      <td>[2.4439504979436975, 0.6585590799053893, 0.574...</td>\n",
       "      <td>[0.31390891916666597, 0.28664277937833305, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>peyer's patch</td>\n",
       "      <td>Rest</td>\n",
       "      <td>[H2-Aa, Tmsb4x, H2-Eb1, Cd74, Mfge8, Ik, H2-Ab...</td>\n",
       "      <td>[200.07019818590464, 44.23749785450635, 22.324...</td>\n",
       "      <td>[2.5447492525905, 0.9646061674999997, 2.530380...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    genotype_1 genotype_2 sex_1 sex_2                      AAR1  AAR2  \\\n",
       "0           GF         GF     F     F  crypt apex and crypt mid  Rest   \n",
       "1           GF         GF     F     F     crypt apex and mucosa  Rest   \n",
       "2           GF         GF     F     F                crypt base  Rest   \n",
       "3           GF         GF     F     F                 crypt mid  Rest   \n",
       "4           GF         GF     F     F                epithelium  Rest   \n",
       "..         ...        ...   ...   ...                       ...   ...   \n",
       "139         WT         WT     F     F         mucosa and pellet  Rest   \n",
       "140         WT         WT     F     F       mucosae and interna  Rest   \n",
       "141         WT         WT     F     F      muscle and submucosa  Rest   \n",
       "142         WT         WT     F     F                    pellet  Rest   \n",
       "143         WT         WT     F     F             peyer's patch  Rest   \n",
       "\n",
       "                                                 genes  \\\n",
       "0    [Plac8, Slco6c1, Uckl1, Gm12367, Tspear, Mtmr1...   \n",
       "1    [Mtmr11, Gm32200, Scd4, Cyp2d34, Gimd1, Lyzl4o...   \n",
       "2    [Bpifc, Mapre3, Usp9y, Dydc1, Gm4955, Gm15655,...   \n",
       "3    [Ydjc, Aknad1, Stard4, Rnf4, Phb, Ctc1, Smim4,...   \n",
       "4    [Fgf23, Igkv8-31, Npr1, Gm43705, Tnfsf11, Clec...   \n",
       "..                                                 ...   \n",
       "139  [Saa1, Lypd8, Car4, Abcb1a, Sepp1, Hist1h1c, P...   \n",
       "140  [P4ha1, Mylk3, Gm3985, Dhx32, Tmem45a, Nog, Gm...   \n",
       "141  [Cd2, Lrp8os3, Cyp4a10, Oas1g, Gm38073, 493057...   \n",
       "142  [Clca1, Rbm47, Slc26a3, Saa1, Massilistercora-...   \n",
       "143  [H2-Aa, Tmsb4x, H2-Eb1, Cd74, Mfge8, Ik, H2-Ab...   \n",
       "\n",
       "                                                logBFs  \\\n",
       "0    [2.0122117282095053, 1.542921882516165, 1.4583...   \n",
       "1    [0.28519925093975473, 0.029994950489092207, -0...   \n",
       "2    [1.0082060694559545, 0.8305594259474725, 0.734...   \n",
       "3    [3.4466429431031056, 2.533555270712622, 1.4905...   \n",
       "4    [0.21825720536127427, -0.06046643125800337, -0...   \n",
       "..                                                 ...   \n",
       "139  [3.5810409565550567, 1.1435238760455382, 1.131...   \n",
       "140  [1.30868985066532, 1.2956374600132459, 1.14272...   \n",
       "141  [0.2730773858106193, 0.17285301481707396, 0.16...   \n",
       "142  [2.4439504979436975, 0.6585590799053893, 0.574...   \n",
       "143  [200.07019818590464, 44.23749785450635, 22.324...   \n",
       "\n",
       "                                                 Delta  \n",
       "0    [0.65223562354725, 3.8131681028384583, 1.25715...  \n",
       "1    [0.6372250459891668, 1.2219540229105, 0.415214...  \n",
       "2    [2.5167639623125004, 1.8401814456808336, 2.079...  \n",
       "3    [1.937673891208333, 4.860282585321833, 0.70985...  \n",
       "4    [0.05216546580691617, 0.7135883506803333, 0.08...  \n",
       "..                                                 ...  \n",
       "139  [1.142071956405275, 0.5003454392266667, 0.8313...  \n",
       "140  [1.1789173022458332, 2.065658233677333, 2.0385...  \n",
       "141  [1.7318922431808335, 0.30870173119785826, 0.32...  \n",
       "142  [0.31390891916666597, 0.28664277937833305, 0.3...  \n",
       "143  [2.5447492525905, 0.9646061674999997, 2.530380...  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST_top_gene_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves formated DE genes df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sanjavickovic/data/host-microbiome_data/splotch_outputs'\n",
    "ST_top_gene_dict.to_csv(os.path.join(path, 'ST_top_gene_dict_BF0_combined.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
